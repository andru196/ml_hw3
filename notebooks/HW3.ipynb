{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d46d7f80",
   "metadata": {},
   "source": [
    "Импортируем всякое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "17223940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split, \\\n",
    "                    GridSearchCV, \\\n",
    "                    cross_val_score, \\\n",
    "                    StratifiedKFold, \\\n",
    "                    RandomizedSearchCV\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e535cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d2625663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxi(x):\n",
    "    rez = max(x)\n",
    "    for i in range(len(x)):\n",
    "        if (x[i] == rez):\n",
    "            return (rez, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969d916c",
   "metadata": {},
   "source": [
    "Вдруг придётся преоткрыть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96478ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = None\n",
    "test = None\n",
    "def reload_data():\n",
    "    return (pd.read_csv(\"../data/raw/application_train.csv\"), pd.read_csv(\"../data/raw/application_test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4de1e7",
   "metadata": {},
   "source": [
    "Избавимся от y\\n во флагах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e8cab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_to_int(df):\n",
    "    for i in df:\n",
    "        if \"FLAG\" in i:\n",
    "            df[i] = np.where((df[i] == 'Y') | (df[i] == 'y') | (df[i] == 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d69f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = reload_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faacbe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_to_int(train)\n",
    "flag_to_int(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8605ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"TARGET\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fe484f",
   "metadata": {},
   "source": [
    "Достаём часть данных, чтобы ускорить работу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50c55ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_(df):\n",
    "    return df.join(pd.read_csv(\"../data/raw/bureau.csv\"), on='SK_ID_CURR', how='inner', rsuffix='_b').join(pd.read_csv(\"../data/raw/credit_card_balance.csv\"), on='SK_ID_CURR', how='inner', rsuffix='_ccb').join(pd.read_csv(\"../data/raw/previous_application.csv\"), on='SK_ID_CURR', how='inner', rsuffix='_pa').join(pd.read_csv(\"../data/raw/POS_CASH_balance.csv\"), on='SK_ID_CURR', how='inner', rsuffix='_pcb')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6dc6ee",
   "metadata": {},
   "source": [
    "Функция для тестиования и измерения orc auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cc7fd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_roc(df, features, target = \"TARGET\"):\n",
    "    kf = KFold(n_splits=5, shuffle=True) #random_state=42)\n",
    "    \n",
    "    roc_list = []\n",
    "    for i, (train_index, val_index) in enumerate(kf.split(df)):\n",
    "        train_part = df.iloc[train_index, : ]\n",
    "        train_x = train_part[features]\n",
    "        train_y = train_part[target]\n",
    "        \n",
    "        val_part = df.iloc[val_index, :]\n",
    "        test_x = val_part[features]\n",
    "        test_y = val_part[target]\n",
    "        \n",
    "        model = LogisticRegression()\n",
    "        \n",
    "        model.fit(train_x, train_y)\n",
    "        \n",
    "        y_score = model.predict_proba(test_x)[:,1]\n",
    "\n",
    "        roc_auc = roc_auc_score(test_y, y_score)\n",
    "\n",
    "        print(f'Fold full {i}: roc_auc {roc_auc}, count values {y_score}')\n",
    "        roc_list.append(roc_auc)\n",
    "\n",
    "        \n",
    "    print(f'roc average = {np.mean(roc_list)}, std = {np.std(roc_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ba7e33",
   "metadata": {},
   "source": [
    "Функция для тестирования и подсчёта msle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04908a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def comp_mse(df, features, target):\n",
    "    kf = KFold(n_splits=5, shuffle=True) #random_state=42)\n",
    "    \n",
    "    msle_list = []\n",
    "    mse_list = []\n",
    "    for i, (train_index, val_index) in enumerate(kf.split(df)):    \n",
    "        train_part = df.iloc[train_index, : ]\n",
    "        val_part = df.iloc[val_index, :]\n",
    "        model = SGDRegressor()\n",
    "        model.fit(X=train_part[features].fillna(0), y = train_part[target])\n",
    "        val_predication = model.predict(val_part[features].fillna(0)).clip(0, 100000000000)\n",
    "\n",
    "        mse = mean_squared_error(val_predication, val_part[target])\n",
    "        msle = mean_squared_log_error(val_predication, val_part[target])\n",
    "\n",
    "        \n",
    "        print(f'Fold full {i}: msle {msle}, mse {mse}')\n",
    "        msle_list.append(msle)\n",
    "        mse_list.append(mse)\n",
    "        \n",
    "    print(f'MSLE average = {np.mean(msle_list)}, std = {np.std(msle_list)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84359884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_n_write_csv(features, path=\"predict1.csv\"):\n",
    "    target = \"TARGET\"\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    train_part_x = train[features].fillna(0)\n",
    "    train_part_y = train[target]\n",
    "    model.fit(X=train_part_x, y = train_part_y)\n",
    "    \n",
    "    sample_submission = pd.read_csv(\"../data/raw/sample_submission.csv\")\n",
    "    sample_submission[target] = model.predict(test[features]) \n",
    "    sample_submission.to_csv(path, index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89543c84",
   "metadata": {},
   "source": [
    "Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef1ea269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(train, x1, test=None, x2=None):\n",
    "    train = x1(train)\n",
    "    if x2 != None:\n",
    "        test = x2(test)\n",
    "    return (train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f29ba6d",
   "metadata": {},
   "source": [
    "Подцепим флаги из осного сета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ebe2b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = [\"FLAG_MOBIL\", \"FLAG_EMP_PHONE\", \"FLAG_CONT_MOBILE\", \"FLAG_EMAIL\", \"REG_REGION_NOT_WORK_REGION\",\n",
    "        # \"DAYS_LAST_PHONE_CHANGE\", 'REG_REGION_NOT_LIVE_REGION','REG_REGION_NOT_WORK_REGION',\n",
    "         'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY','REG_CITY_NOT_WORK_CITY',\n",
    "            'FLAG_OWN_REALTY', 'FLAG_OWN_CAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fb36605",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p = train[train[target] == 1]\n",
    "train_m = train[train[target] == 0].sample(train_p.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aede6bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = train_p.append(train_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e344cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8e4c9aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_object_and_convert_bits(train_1):\n",
    "    i = 0\n",
    "    for i in train_1:\n",
    "        if train_1.dtypes[i] == object:\n",
    "            if len(train_1[\"NAME_CONTRACT_TYPE\"].unique())  == 2:\n",
    "                LE = LabelEncoder()\n",
    "                train_1[i] = LE.fit_transform(train_1[i])\n",
    "\n",
    "            else:\n",
    "                print(i, \"\\t\\t\", train_1.dtypes[i])\n",
    "                i += 1\n",
    "    if i == 0:\n",
    "        print(\"only bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85675f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_object_and_convert_bits(train_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bec7ea4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:28:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier()\n",
    "model.fit(train_1.drop(target, axis=1), train_1[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ec078c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_object_and_convert_bits(test)\n",
    "y_pred = model.predict(test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0a953f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../data/raw/sample_submission.csv\")\n",
    "sample_submission[target] = y_pred\n",
    "sample_submission.to_csv(\"first_predict.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f545382d",
   "metadata": {},
   "source": [
    "### Private Score 0.67256\n",
    "### Public Score 0.67929"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5412c6f",
   "metadata": {},
   "source": [
    "По заданию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0d78ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    " = join_(train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a06e30cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_object_and_convert_bits(train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfe49488",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>DAYS_TERMINATION</th>\n",
       "      <th>NFLAG_INSURED_ON_APPROVAL</th>\n",
       "      <th>SK_ID_PREV_pcb</th>\n",
       "      <th>SK_ID_CURR_pcb</th>\n",
       "      <th>MONTHS_BALANCE_pcb</th>\n",
       "      <th>CNT_INSTALMENT</th>\n",
       "      <th>CNT_INSTALMENT_FUTURE</th>\n",
       "      <th>NAME_CONTRACT_STATUS_pcb</th>\n",
       "      <th>SK_DPD_pcb</th>\n",
       "      <th>SK_DPD_DEF_pcb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-1908.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2415125</td>\n",
       "      <td>200227</td>\n",
       "      <td>-32</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100031</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>979992.0</td>\n",
       "      <td>27076.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-258.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2706181</td>\n",
       "      <td>135757</td>\n",
       "      <td>-38</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>100047</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>1193580.0</td>\n",
       "      <td>35028.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-546.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1940977</td>\n",
       "      <td>138382</td>\n",
       "      <td>-2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>100049</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>288873.0</td>\n",
       "      <td>16258.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2674796</td>\n",
       "      <td>384799</td>\n",
       "      <td>-10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>100096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>252000.0</td>\n",
       "      <td>14593.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2726442</td>\n",
       "      <td>245973</td>\n",
       "      <td>-7</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272760</th>\n",
       "      <td>416187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>1087366.5</td>\n",
       "      <td>31923.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2748910</td>\n",
       "      <td>235906</td>\n",
       "      <td>-53</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64909</th>\n",
       "      <td>175270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>1546020.0</td>\n",
       "      <td>40783.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-2251.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2607838</td>\n",
       "      <td>198900</td>\n",
       "      <td>-9</td>\n",
       "      <td>36.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114394</th>\n",
       "      <td>232658</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>11074.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-1027.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2272203</td>\n",
       "      <td>343209</td>\n",
       "      <td>-25</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223704</th>\n",
       "      <td>359104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>1125000.0</td>\n",
       "      <td>32895.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1671452</td>\n",
       "      <td>296280</td>\n",
       "      <td>-49</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138953</th>\n",
       "      <td>261122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>12375.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2687494</td>\n",
       "      <td>428318</td>\n",
       "      <td>-41</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49650 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  TARGET  NAME_CONTRACT_TYPE  CODE_GENDER  FLAG_OWN_CAR  \\\n",
       "0           100002       1                   0            1             0   \n",
       "26          100031       1                   0            0             0   \n",
       "40          100047       1                   0            1             0   \n",
       "42          100049       1                   0            0             0   \n",
       "81          100096       1                   0            0             0   \n",
       "...            ...     ...                 ...          ...           ...   \n",
       "272760      416187       0                   0            1             1   \n",
       "64909       175270       0                   0            0             1   \n",
       "114394      232658       0                   0            1             0   \n",
       "223704      359104       0                   0            0             0   \n",
       "138953      261122       0                   1            1             1   \n",
       "\n",
       "        FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
       "0                     1             0          202500.0    406597.5   \n",
       "26                    1             0          112500.0    979992.0   \n",
       "40                    1             0          202500.0   1193580.0   \n",
       "42                    0             0          135000.0    288873.0   \n",
       "81                    1             0           81000.0    252000.0   \n",
       "...                 ...           ...               ...         ...   \n",
       "272760                1             0          112500.0   1087366.5   \n",
       "64909                 1             0          450000.0   1546020.0   \n",
       "114394                1             1          121500.0    225000.0   \n",
       "223704                1             0          112500.0   1125000.0   \n",
       "138953                0             0           90000.0    247500.0   \n",
       "\n",
       "        AMT_ANNUITY  ...  DAYS_TERMINATION  NFLAG_INSURED_ON_APPROVAL  \\\n",
       "0           24700.5  ...           -1908.0                        0.0   \n",
       "26          27076.5  ...            -258.0                        1.0   \n",
       "40          35028.0  ...            -546.0                        1.0   \n",
       "42          16258.5  ...               NaN                        NaN   \n",
       "81          14593.5  ...               NaN                        NaN   \n",
       "...             ...  ...               ...                        ...   \n",
       "272760      31923.0  ...               NaN                        NaN   \n",
       "64909       40783.5  ...           -2251.0                        0.0   \n",
       "114394      11074.5  ...           -1027.0                        0.0   \n",
       "223704      32895.0  ...               NaN                        NaN   \n",
       "138953      12375.0  ...               NaN                        NaN   \n",
       "\n",
       "        SK_ID_PREV_pcb  SK_ID_CURR_pcb  MONTHS_BALANCE_pcb  CNT_INSTALMENT  \\\n",
       "0              2415125          200227                 -32            12.0   \n",
       "26             2706181          135757                 -38             6.0   \n",
       "40             1940977          138382                  -2            12.0   \n",
       "42             2674796          384799                 -10            36.0   \n",
       "81             2726442          245973                  -7            13.0   \n",
       "...                ...             ...                 ...             ...   \n",
       "272760         2748910          235906                 -53            30.0   \n",
       "64909          2607838          198900                  -9            36.0   \n",
       "114394         2272203          343209                 -25            10.0   \n",
       "223704         1671452          296280                 -49            12.0   \n",
       "138953         2687494          428318                 -41            18.0   \n",
       "\n",
       "        CNT_INSTALMENT_FUTURE  NAME_CONTRACT_STATUS_pcb  SK_DPD_pcb  \\\n",
       "0                        12.0                         0           0   \n",
       "26                        6.0                         0           0   \n",
       "40                        2.0                         0           0   \n",
       "42                       16.0                         0           0   \n",
       "81                        0.0                         2           0   \n",
       "...                       ...                       ...         ...   \n",
       "272760                    1.0                         0           0   \n",
       "64909                    21.0                         0           0   \n",
       "114394                    3.0                         0           0   \n",
       "223704                    2.0                         0           0   \n",
       "138953                    7.0                         0           0   \n",
       "\n",
       "        SK_DPD_DEF_pcb  \n",
       "0                    0  \n",
       "26                   0  \n",
       "40                   0  \n",
       "42                   0  \n",
       "81                   0  \n",
       "...                ...  \n",
       "272760               0  \n",
       "64909                0  \n",
       "114394               0  \n",
       "223704               0  \n",
       "138953               0  \n",
       "\n",
       "[49650 rows x 207 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1161fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "920786c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=range(1, 7), min_child_weight=11, missing=-999, n_estimators=range(3, 8), nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.2s\n",
      "[18:28:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.7s\n",
      "[18:28:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.1s\n",
      "[18:28:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=range(1, 7), min_child_weight=11, missing=-999, n_estimators=range(3, 8), nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.2s\n",
      "[18:28:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.7s\n",
      "[18:28:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.7s\n",
      "[18:28:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=range(1, 7), min_child_weight=11, missing=-999, n_estimators=range(3, 8), nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.2s\n",
      "[18:28:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.7s\n",
      "[18:28:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.1s\n",
      "[18:28:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=range(1, 7), min_child_weight=11, missing=-999, n_estimators=range(3, 8), nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.2s\n",
      "[18:28:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.7s\n",
      "[18:28:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.7s\n",
      "[18:28:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.4s\n",
      "[18:28:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=range(1, 7), min_child_weight=11, missing=-999, n_estimators=range(3, 8), nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.2s\n",
      "[18:28:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.7s\n",
      "[18:28:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.1s\n",
      "[18:28:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.3s\n",
      "[18:28:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.5s\n",
      "[18:28:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.3s\n",
      "[18:28:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.8s\n",
      "[18:28:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.4s\n",
      "[18:28:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.3s\n",
      "[18:28:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.8s\n",
      "[18:28:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.0s\n",
      "[18:28:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.3s\n",
      "[18:28:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.4s\n",
      "[18:28:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.4s\n",
      "[18:28:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.0s\n",
      "[18:28:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.3s\n",
      "[18:28:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.3s\n",
      "[18:28:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.7s\n",
      "[18:28:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.5s\n",
      "[18:28:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.1s\n",
      "[18:28:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.3s\n",
      "[18:28:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.4s\n",
      "[18:28:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.8s\n",
      "[18:28:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.4s\n",
      "[18:28:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.7s\n",
      "[18:28:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.8s\n",
      "[18:28:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.4s\n",
      "[18:28:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.1s\n",
      "[18:28:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.4s\n",
      "[18:28:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.8s\n",
      "[18:28:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.8s\n",
      "[18:28:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.0s\n",
      "[18:28:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.5s\n",
      "[18:28:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.4s\n",
      "[18:28:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.3s\n",
      "[18:28:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.1s\n",
      "[18:28:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.5s\n",
      "[18:28:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.8s\n",
      "[18:28:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.9s\n",
      "[18:28:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.2s\n",
      "[18:28:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.3s\n",
      "[18:28:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.9s\n",
      "[18:28:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.3s\n",
      "[18:28:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.8s\n",
      "[18:28:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.5s\n",
      "[18:28:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.8s\n",
      "[18:28:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.1s\n",
      "[18:28:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.1s\n",
      "[18:28:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.4s\n",
      "[18:28:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.4s\n",
      "[18:28:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.5s\n",
      "[18:28:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.0s\n",
      "[18:28:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.3s\n",
      "[18:28:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.7s\n",
      "[18:28:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.2s\n",
      "[18:28:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.8s\n",
      "[18:28:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.9s\n",
      "[18:28:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.4s\n",
      "[18:28:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.9s\n",
      "[18:28:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.9s\n",
      "[18:28:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.1s\n",
      "[18:28:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.8s\n",
      "[18:28:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:28:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1,\n",
       "                                     enable_categorical=False, gamma=0,\n",
       "                                     gpu_id=-1, importance_type=None,\n",
       "                                     interaction_constraints='',\n",
       "                                     learning_rate=0.300000012,\n",
       "                                     max_delta_step=0, max_depth=6,\n",
       "                                     min_child_weigh...\n",
       "                                     scale_pos_weight=1, subsample=1,\n",
       "                                     tree_method='exact', validate_parameters=1,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=5,\n",
       "             param_grid={'colsample_bytree': [0.7], 'learning_rate': [0.05],\n",
       "                         'max_depth': range(1, 7), 'min_child_weight': [11],\n",
       "                         'missing': [-999], 'n_estimators': range(3, 8),\n",
       "                         'nthread': [4], 'objective': ['binary:logistic'],\n",
       "                         'seed': [1337], 'silent': [1], 'subsample': [0.8]},\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'nthread':[4],\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05],\n",
    "              'max_depth': range(1, 7),\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': range(3,8),\n",
    "              'missing':[-999],\n",
    "              'seed': [1337]}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(model, parameters, n_jobs=5, \n",
    "                   cv=StratifiedKFold(n_splits=5, shuffle=True),\n",
    "                   scoring='roc_auc',\n",
    "                   verbose=2, refit=True)\n",
    "\n",
    "clf.fit(train_1.drop(target, axis=1), train_1[target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "504dd92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.66224499, 0.71892977, 0.78048882, 0.84588103, 0.88025627,\n",
       "        0.77139254, 0.88258176, 0.98155403, 1.1235806 , 1.17926841,\n",
       "        0.87364964, 1.10652065, 1.25857639, 1.47057433, 1.60815501,\n",
       "        1.08856688, 1.30723848, 1.63559833, 1.83993645, 2.4305512 ,\n",
       "        1.32007523, 1.72751637, 1.97278786, 2.14415712, 2.55757103,\n",
       "        1.44982572, 1.96283545, 2.11128435, 2.62360325, 2.89891081]),\n",
       " 'std_fit_time': array([0.02221718, 0.02558428, 0.03594242, 0.03570055, 0.03325041,\n",
       "        0.0361022 , 0.07433078, 0.04287862, 0.10601879, 0.04435179,\n",
       "        0.06078401, 0.08286941, 0.07045421, 0.07698871, 0.10311997,\n",
       "        0.08751746, 0.05355422, 0.08195888, 0.16309078, 0.16813131,\n",
       "        0.18979523, 0.03263787, 0.20421059, 0.15690695, 0.2624887 ,\n",
       "        0.11627625, 0.16001514, 0.08245214, 0.19288925, 0.21908936]),\n",
       " 'mean_score_time': array([0.03896122, 0.03738155, 0.04585795, 0.05064702, 0.04610353,\n",
       "        0.04689531, 0.05376954, 0.06228809, 0.05759311, 0.05421157,\n",
       "        0.05952516, 0.06764503, 0.05402279, 0.06099892, 0.05655131,\n",
       "        0.05657301, 0.06237803, 0.05141301, 0.08063674, 0.05110579,\n",
       "        0.05797105, 0.07038274, 0.06399755, 0.06592183, 0.05594811,\n",
       "        0.05588059, 0.04876108, 0.0575357 , 0.06935253, 0.03821578]),\n",
       " 'std_score_time': array([0.00810968, 0.00478212, 0.00575565, 0.0122953 , 0.00737763,\n",
       "        0.0129709 , 0.01453185, 0.01348294, 0.01006557, 0.00940064,\n",
       "        0.00508918, 0.01035651, 0.00401132, 0.0073636 , 0.01820303,\n",
       "        0.00640339, 0.01741797, 0.0119196 , 0.03553762, 0.0160149 ,\n",
       "        0.00621962, 0.02822669, 0.00476251, 0.01123964, 0.01299084,\n",
       "        0.01526319, 0.00909367, 0.00659762, 0.01296668, 0.01245744]),\n",
       " 'param_colsample_bytree': masked_array(data=[0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "                    0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "                    0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "                    0.05, 0.05, 0.05],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4,\n",
       "                    4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_child_weight': masked_array(data=[11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "                    11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "                    11, 11],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_missing': masked_array(data=[-999, -999, -999, -999, -999, -999, -999, -999, -999,\n",
       "                    -999, -999, -999, -999, -999, -999, -999, -999, -999,\n",
       "                    -999, -999, -999, -999, -999, -999, -999, -999, -999,\n",
       "                    -999, -999, -999],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[3, 4, 5, 6, 7, 3, 4, 5, 6, 7, 3, 4, 5, 6, 7, 3, 4, 5,\n",
       "                    6, 7, 3, 4, 5, 6, 7, 3, 4, 5, 6, 7],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_nthread': masked_array(data=[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_objective': masked_array(data=['binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_seed': masked_array(data=[1337, 1337, 1337, 1337, 1337, 1337, 1337, 1337, 1337,\n",
       "                    1337, 1337, 1337, 1337, 1337, 1337, 1337, 1337, 1337,\n",
       "                    1337, 1337, 1337, 1337, 1337, 1337, 1337, 1337, 1337,\n",
       "                    1337, 1337, 1337],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_silent': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_subsample': masked_array(data=[0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 1,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 3,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 1,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 4,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 1,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 5,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 1,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 6,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 1,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 7,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 3,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 4,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 5,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 6,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 7,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 3,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 4,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 5,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 6,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 7,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 3,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 4,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 5,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 6,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 7,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 3,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 4,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 5,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 6,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 7,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 3,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 4,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 5,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 6,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 7,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8}],\n",
       " 'split0_test_score': array([0.65889285, 0.66305384, 0.66500198, 0.66715628, 0.67317955,\n",
       "        0.67426718, 0.68017577, 0.67967129, 0.69318797, 0.69672373,\n",
       "        0.68938114, 0.69732961, 0.69859224, 0.70781418, 0.71286567,\n",
       "        0.70138433, 0.71002135, 0.71103641, 0.71872538, 0.72308567,\n",
       "        0.70991283, 0.71807239, 0.71821481, 0.72505563, 0.72848179,\n",
       "        0.71460783, 0.72387192, 0.72403296, 0.72956873, 0.73302231]),\n",
       " 'split1_test_score': array([0.6724791 , 0.6744465 , 0.67494575, 0.68033447, 0.68190394,\n",
       "        0.69046968, 0.69361695, 0.69502871, 0.70565552, 0.71305688,\n",
       "        0.70438579, 0.70909028, 0.71062012, 0.71886202, 0.72289452,\n",
       "        0.71324261, 0.72023451, 0.71950313, 0.72597836, 0.73025485,\n",
       "        0.71779137, 0.72473601, 0.72404633, 0.73052106, 0.73372772,\n",
       "        0.71975492, 0.72685822, 0.72603889, 0.73222191, 0.73571806]),\n",
       " 'split2_test_score': array([0.66888528, 0.67314454, 0.67580972, 0.6810238 , 0.68332284,\n",
       "        0.68477039, 0.68986732, 0.69146195, 0.70450387, 0.71005518,\n",
       "        0.70028031, 0.70741795, 0.7084824 , 0.71740273, 0.72206925,\n",
       "        0.71295406, 0.7191315 , 0.71965089, 0.72734852, 0.73080693,\n",
       "        0.7190108 , 0.72579991, 0.72596956, 0.73215467, 0.73500295,\n",
       "        0.72373326, 0.72997103, 0.73024365, 0.73482971, 0.7364845 ]),\n",
       " 'split3_test_score': array([0.66200824, 0.66302366, 0.6641616 , 0.67186724, 0.67165017,\n",
       "        0.67489056, 0.68105826, 0.68077637, 0.69346911, 0.70077201,\n",
       "        0.69248248, 0.69882034, 0.69875696, 0.70743624, 0.71349189,\n",
       "        0.70112465, 0.70948275, 0.70922425, 0.71696131, 0.7218382 ,\n",
       "        0.71147322, 0.71847212, 0.71700485, 0.72460429, 0.72836395,\n",
       "        0.71578467, 0.72226196, 0.72053985, 0.72758916, 0.73094307]),\n",
       " 'split4_test_score': array([0.66273467, 0.66866809, 0.66768148, 0.6710991 , 0.67560237,\n",
       "        0.67628377, 0.68064338, 0.67755286, 0.69768304, 0.70270088,\n",
       "        0.69495561, 0.70168864, 0.70146534, 0.71113872, 0.71700143,\n",
       "        0.70666989, 0.71210686, 0.71246751, 0.71994152, 0.72471321,\n",
       "        0.71279719, 0.71859173, 0.71925373, 0.72541993, 0.73020408,\n",
       "        0.71808961, 0.7244698 , 0.72443313, 0.73022191, 0.733582  ]),\n",
       " 'mean_test_score': array([0.66500003, 0.66846733, 0.66952011, 0.67429618, 0.67713177,\n",
       "        0.68013632, 0.68507234, 0.68489824, 0.6988999 , 0.70466174,\n",
       "        0.69629706, 0.70286936, 0.70358341, 0.71253078, 0.71766455,\n",
       "        0.70707511, 0.7141954 , 0.71437644, 0.72179102, 0.72613977,\n",
       "        0.71419708, 0.72113443, 0.72089786, 0.72755112, 0.73115609,\n",
       "        0.71839406, 0.72548658, 0.7250577 , 0.73088628, 0.73394999]),\n",
       " 'std_test_score': array([0.00494797, 0.00482921, 0.00492959, 0.00545566, 0.0046714 ,\n",
       "        0.00640406, 0.00558045, 0.00698533, 0.00530365, 0.00602585,\n",
       "        0.00539396, 0.00464472, 0.0050241 , 0.00477408, 0.0041865 ,\n",
       "        0.00530202, 0.00457886, 0.00436916, 0.00411253, 0.00370357,\n",
       "        0.0035728 , 0.0033961 , 0.00348403, 0.00314536, 0.00273005,\n",
       "        0.00321236, 0.00268443, 0.00315303, 0.00246507, 0.00197926]),\n",
       " 'rank_test_score': array([30, 29, 28, 27, 26, 25, 23, 24, 21, 18, 22, 20, 19, 16, 12, 17, 15,\n",
       "        13,  8,  5, 14,  9, 10,  4,  2, 11,  6,  7,  3,  1], dtype=int32)}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e368d7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_fit_time\n",
      "std_fit_time\n",
      "mean_score_time\n",
      "std_score_time\n",
      "param_colsample_bytree\n",
      "param_learning_rate\n",
      "param_max_depth\n",
      "param_min_child_weight\n",
      "param_missing\n",
      "param_n_estimators\n",
      "param_nthread\n",
      "param_objective\n",
      "param_seed\n",
      "param_silent\n",
      "param_subsample\n",
      "params\n",
      "split0_test_score\n",
      "split1_test_score\n",
      "split2_test_score\n",
      "split3_test_score\n",
      "split4_test_score\n",
      "mean_test_score\n",
      "std_test_score\n",
      "rank_test_score\n"
     ]
    }
   ],
   "source": [
    "for i in clf.cv_results_.keys():\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf7cc4c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7339499882865862 \n",
      " {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 11, 'missing': -999, 'n_estimators': 7, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "score, i = maxi(clf.cv_results_['mean_test_score'])\n",
    "params = clf.cv_results_['params'][i]\n",
    "print (score, \"\\n\", params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ed8bda",
   "metadata": {},
   "source": [
    "теперь RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e841388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(use_label_encoder=False)\n",
    "parameters = {'nthread':[4],\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.001, 0.05, 0.1, 0.2, 0,3],\n",
    "              'max_depth': range(1, 20),\n",
    "              'min_child_weight': np.arange(0.5, 20, 0.5),\n",
    "              'gamma': [0, 0.25, 0.5, 1.0],\n",
    "              'subsample': np.arange(0.4, 1, 0.1),\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [3,10, 20, 50, 100],\n",
    "              'missing':[-999],\n",
    "              'seed': [1337]}\n",
    "fit_params = {'eval_metric': 'mlogloss',\n",
    "              'early_stopping_rounds': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d9b07e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_clf = RandomizedSearchCV(model, parameters, n_iter=20,\n",
    "                            n_jobs=5, verbose=2,\n",
    "                            cv=StratifiedKFold(n_splits=5, shuffle=True),\n",
    "                            scoring='roc_auc', refit=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1cc63ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[19:50:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=3, max_depth=10, min_child_weight=5.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=   5.0s\n",
      "[19:50:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=3, max_depth=18, min_child_weight=15.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7999999999999999; total time=   8.0s\n",
      "[19:50:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0, max_depth=9, min_child_weight=13.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  24.2s\n",
      "[19:51:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=3, max_depth=13, min_child_weight=10.5, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=   4.6s\n",
      "[19:51:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0, max_depth=19, min_child_weight=5.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  44.0s\n",
      "[19:52:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=9, min_child_weight=18.0, missing=-999, n_estimators=20, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7999999999999999; total time=  10.8s\n",
      "[19:52:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.001, max_depth=4, min_child_weight=7.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=  23.8s\n",
      "[19:52:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=3, max_depth=9, min_child_weight=13.5, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=   2.2s\n",
      "[19:52:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=3, max_depth=9, min_child_weight=13.5, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=   2.3s\n",
      "[19:52:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=3, max_depth=9, min_child_weight=13.5, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=   1.8s\n",
      "[19:52:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.2, max_depth=18, min_child_weight=15.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  38.7s\n",
      "[19:53:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.05, max_depth=17, min_child_weight=15.0, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   3.5s\n",
      "[19:53:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.1, max_depth=12, min_child_weight=10.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time= 1.2min\n",
      "[19:54:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.001, max_depth=10, min_child_weight=15.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time=   6.4s\n",
      "[19:54:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=17, min_child_weight=2.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time= 1.1min\n",
      "[19:55:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=16, min_child_weight=10.0, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time= 1.5min\n",
      "[19:57:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=18, min_child_weight=8.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=  53.7s\n",
      "[19:58:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:50:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=3, max_depth=10, min_child_weight=5.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=   5.1s\n",
      "[19:50:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=3, max_depth=18, min_child_weight=15.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7999999999999999; total time=   7.7s\n",
      "[19:50:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0, max_depth=9, min_child_weight=13.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  26.5s\n",
      "[19:51:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=3, max_depth=13, min_child_weight=10.5, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=   5.2s\n",
      "[19:51:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0, max_depth=19, min_child_weight=5.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  44.5s\n",
      "[19:52:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=9, min_child_weight=18.0, missing=-999, n_estimators=20, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7999999999999999; total time=  13.1s\n",
      "[19:52:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.001, max_depth=4, min_child_weight=7.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=  23.8s\n",
      "[19:52:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=3, max_depth=9, min_child_weight=13.5, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=   2.3s\n",
      "[19:52:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.2, max_depth=18, min_child_weight=15.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  36.3s\n",
      "[19:53:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.05, max_depth=17, min_child_weight=15.0, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   2.6s\n",
      "[19:53:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.1, max_depth=12, min_child_weight=10.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time= 1.2min\n",
      "[19:54:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.001, max_depth=10, min_child_weight=15.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time=   5.7s\n",
      "[19:54:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=17, min_child_weight=2.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=  59.8s\n",
      "[19:55:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=16, min_child_weight=10.0, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time= 1.5min\n",
      "[19:57:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=18, min_child_weight=8.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=  52.9s\n",
      "[19:57:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=2.5, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   8.3s\n",
      "[19:58:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=2.5, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   8.2s\n",
      "[19:58:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:50:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=3, max_depth=10, min_child_weight=5.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=   4.6s\n",
      "[19:50:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=3, max_depth=18, min_child_weight=15.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7999999999999999; total time=   8.0s\n",
      "[19:50:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0, max_depth=9, min_child_weight=13.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  23.5s\n",
      "[19:51:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=3, max_depth=13, min_child_weight=10.5, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=   5.3s\n",
      "[19:51:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0, max_depth=19, min_child_weight=5.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  48.6s\n",
      "[19:52:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=9, min_child_weight=18.0, missing=-999, n_estimators=20, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7999999999999999; total time=  11.8s\n",
      "[19:52:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.001, max_depth=4, min_child_weight=7.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=  24.6s\n",
      "[19:52:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.2, max_depth=18, min_child_weight=15.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  34.3s\n",
      "[19:53:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.05, max_depth=17, min_child_weight=15.0, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   3.3s\n",
      "[19:53:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.05, max_depth=17, min_child_weight=15.0, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   2.8s\n",
      "[19:53:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.1, max_depth=12, min_child_weight=10.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time= 1.2min\n",
      "[19:54:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.001, max_depth=10, min_child_weight=15.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time=   7.4s\n",
      "[19:54:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=17, min_child_weight=2.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time= 1.0min\n",
      "[19:55:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=16, min_child_weight=10.0, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time= 1.4min\n",
      "[19:57:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=18, min_child_weight=8.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=  52.6s\n",
      "[19:57:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=2.5, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   8.5s\n",
      "[19:58:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=2.5, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   8.2s\n",
      "[19:58:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:50:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=3, max_depth=10, min_child_weight=5.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=   4.2s\n",
      "[19:50:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=3, max_depth=18, min_child_weight=15.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7999999999999999; total time=   7.5s\n",
      "[19:50:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0, max_depth=9, min_child_weight=13.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  25.1s\n",
      "[19:51:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=3, max_depth=13, min_child_weight=10.5, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=   4.5s\n",
      "[19:51:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=3, max_depth=13, min_child_weight=10.5, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=   4.9s\n",
      "[19:51:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0, max_depth=19, min_child_weight=5.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  46.9s\n",
      "[19:52:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=9, min_child_weight=18.0, missing=-999, n_estimators=20, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7999999999999999; total time=  12.4s\n",
      "[19:52:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.001, max_depth=4, min_child_weight=7.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=  24.0s\n",
      "[19:52:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.2, max_depth=18, min_child_weight=15.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  38.6s\n",
      "[19:53:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.1, max_depth=12, min_child_weight=10.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time= 1.2min\n",
      "[19:54:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.001, max_depth=10, min_child_weight=15.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time=   5.0s\n",
      "[19:54:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=17, min_child_weight=2.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time= 1.1min\n",
      "[19:55:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=16, min_child_weight=10.0, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time= 1.5min\n",
      "[19:57:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=18, min_child_weight=8.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=  52.5s\n",
      "[19:58:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=14, min_child_weight=11.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   9.1s\n",
      "[19:58:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.1, max_depth=19, min_child_weight=2.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time= 1.2min\n",
      "[19:59:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0, max_depth=13, min_child_weight=7.0, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.8999999999999999; total time=   3.9s\n",
      "[19:59:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:50:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=3, max_depth=10, min_child_weight=5.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=   5.5s\n",
      "[19:50:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=3, max_depth=18, min_child_weight=15.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7999999999999999; total time=   8.5s\n",
      "[19:50:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0, max_depth=9, min_child_weight=13.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  27.7s\n",
      "[19:51:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0, max_depth=19, min_child_weight=5.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  49.2s\n",
      "[19:52:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=9, min_child_weight=18.0, missing=-999, n_estimators=20, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7999999999999999; total time=  11.9s\n",
      "[19:52:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.001, max_depth=4, min_child_weight=7.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=  22.5s\n",
      "[19:52:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=3, max_depth=9, min_child_weight=13.5, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=   1.4s\n",
      "[19:52:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.2, max_depth=18, min_child_weight=15.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  37.1s\n",
      "[19:53:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.05, max_depth=17, min_child_weight=15.0, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   2.9s\n",
      "[19:53:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.1, max_depth=12, min_child_weight=10.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time= 1.1min\n",
      "[19:54:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.001, max_depth=10, min_child_weight=15.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time=   5.8s\n",
      "[19:54:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=17, min_child_weight=2.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time= 1.1min\n",
      "[19:55:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=16, min_child_weight=10.0, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time= 1.5min\n",
      "[19:57:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=18, min_child_weight=8.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=  55.5s\n",
      "[19:58:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=2.5, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   8.1s\n",
      "[19:58:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=14, min_child_weight=11.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   8.2s\n",
      "[19:58:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.1, max_depth=19, min_child_weight=2.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time= 1.2min\n",
      "[19:59:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:00:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           enable_categorical=False, gamma=None,\n",
       "                                           gpu_id=None, importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=No...\n",
       "                                        'min_child_weight': array([ 0.5,  1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,  5. ,  5.5,\n",
       "        6. ,  6.5,  7. ,  7.5,  8. ,  8.5,  9. ,  9.5, 10. , 10.5, 11. ,\n",
       "       11.5, 12. , 12.5, 13. , 13.5, 14. , 14.5, 15. , 15.5, 16. , 16.5,\n",
       "       17. , 17.5, 18. , 18.5, 19. , 19.5]),\n",
       "                                        'missing': [-999],\n",
       "                                        'n_estimators': [3, 10, 20, 50, 100],\n",
       "                                        'nthread': [4],\n",
       "                                        'objective': ['binary:logistic'],\n",
       "                                        'seed': [1337],\n",
       "                                        'subsample': array([0.4, 0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "                   random_state=42, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_clf.fit(train_1.drop(target, axis=1), train_1[target])\n",
    "#            **, fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "25333a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7413391788846193 {'subsample': 0.7999999999999999, 'seed': 1337, 'objective': 'binary:logistic', 'nthread': 4, 'n_estimators': 20, 'missing': -999, 'min_child_weight': 18.0, 'max_depth': 9, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 0.7}\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0, max_depth=13, min_child_weight=7.0, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.8999999999999999; total time=   2.6s\n",
      "[19:59:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0, max_depth=13, min_child_weight=7.0, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.8999999999999999; total time=   3.7s\n",
      "[19:59:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0, max_depth=12, min_child_weight=10.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time= 1.3min\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0, max_depth=12, min_child_weight=10.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time= 1.3min\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=14, min_child_weight=11.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   9.7s\n",
      "[19:58:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.1, max_depth=19, min_child_weight=2.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time= 1.1min\n",
      "[19:59:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0, max_depth=12, min_child_weight=10.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time= 1.3min\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=14, min_child_weight=11.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=  10.1s\n",
      "[19:58:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.1, max_depth=19, min_child_weight=2.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time= 1.2min\n",
      "[19:59:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0, max_depth=12, min_child_weight=10.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time= 1.3min\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=14, min_child_weight=11.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=  10.2s\n",
      "[19:58:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.1, max_depth=19, min_child_weight=2.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time= 1.1min\n",
      "[19:59:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0, max_depth=13, min_child_weight=7.0, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.8999999999999999; total time=   3.9s\n",
      "[19:59:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0, max_depth=13, min_child_weight=7.0, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.8999999999999999; total time=   3.5s\n",
      "[19:59:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0, max_depth=12, min_child_weight=10.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time= 1.3min\n"
     ]
    }
   ],
   "source": [
    "print(rs_clf.best_score_, rs_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "93da62bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:13:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.7,\n",
       "              enable_categorical=False, gamma=0, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=9,\n",
       "              min_child_weight=18.0, missing=-999, monotone_constraints='()',\n",
       "              n_estimators=20, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
       "              predictor='auto', random_state=1337, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, seed=1337, subsample=0.7999999999999999,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, ...)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(use_label_encoder=False, **rs_clf.best_params_)\n",
    "model.fit(train_1.drop(target, axis=1), train_1[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "65eb0a10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance = list(filter(lambda x: x > 0.001, model.feature_importances_))\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
