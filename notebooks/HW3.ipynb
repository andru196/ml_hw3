{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d46d7f80",
   "metadata": {},
   "source": [
    "Импортируем всякое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "17223940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split, \\\n",
    "                    GridSearchCV, \\\n",
    "                    cross_val_score, \\\n",
    "                    StratifiedKFold, \\\n",
    "                    RandomizedSearchCV\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e535cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d2625663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxi(x):\n",
    "    rez = max(x)\n",
    "    for i in range(len(x)):\n",
    "        if (x[i] == rez):\n",
    "            return (rez, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969d916c",
   "metadata": {},
   "source": [
    "Вдруг придётся преоткрыть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96478ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = None\n",
    "test = None\n",
    "def reload_data():\n",
    "    return (pd.read_csv(\"../data/raw/application_train.csv\"), pd.read_csv(\"../data/raw/application_test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4de1e7",
   "metadata": {},
   "source": [
    "Избавимся от y\\n во флагах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e8cab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_to_int(df):\n",
    "    for i in df:\n",
    "        if \"FLAG\" in i:\n",
    "            df[i] = np.where((df[i] == 'Y') | (df[i] == 'y') | (df[i] == 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d69f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = reload_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faacbe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_to_int(train)\n",
    "flag_to_int(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8605ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"TARGET\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fe484f",
   "metadata": {},
   "source": [
    "Достаём часть данных, чтобы ускорить работу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50c55ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_(df):\n",
    "    return df.join(pd.read_csv(\"../data/raw/bureau.csv\"), on='SK_ID_CURR', how='inner', rsuffix='_b').join(pd.read_csv(\"../data/raw/credit_card_balance.csv\"), on='SK_ID_CURR', how='inner', rsuffix='_ccb').join(pd.read_csv(\"../data/raw/previous_application.csv\"), on='SK_ID_CURR', how='inner', rsuffix='_pa').join(pd.read_csv(\"../data/raw/POS_CASH_balance.csv\"), on='SK_ID_CURR', how='inner', rsuffix='_pcb')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89543c84",
   "metadata": {},
   "source": [
    "Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f29ba6d",
   "metadata": {},
   "source": [
    "Подцепим флаги из осного сета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fb36605",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p = train[train[target] == 1]\n",
    "train_m = train[train[target] == 0].sample(train_p.shape[0])\n",
    "train_1 = train_p.append(train_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e344cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8e4c9aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_object_and_convert_bits(train_1):\n",
    "    i = 0\n",
    "    for i in train_1:\n",
    "        if train_1.dtypes[i] == object:\n",
    "            if len(train_1[\"NAME_CONTRACT_TYPE\"].unique())  == 2:\n",
    "                LE = LabelEncoder()\n",
    "                train_1[i] = LE.fit_transform(train_1[i])\n",
    "\n",
    "            else:\n",
    "                print(i, \"\\t\\t\", train_1.dtypes[i])\n",
    "                i += 1\n",
    "    if i == 0:\n",
    "        print(\"only bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85675f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_object_and_convert_bits(train_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bec7ea4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:28:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier()\n",
    "model.fit(train_1.drop(target, axis=1), train_1[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ec078c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_object_and_convert_bits(test)\n",
    "y_pred = model.predict(test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0a953f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../data/raw/sample_submission.csv\")\n",
    "sample_submission[target] = y_pred\n",
    "sample_submission.to_csv(\"first_predict.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f545382d",
   "metadata": {},
   "source": [
    "### Private Score 0.67256\n",
    "### Public Score 0.67929"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5412c6f",
   "metadata": {},
   "source": [
    "По заданию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0d78ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    " train_1 = join_(train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a06e30cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_object_and_convert_bits(train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfe49488",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>DAYS_TERMINATION</th>\n",
       "      <th>NFLAG_INSURED_ON_APPROVAL</th>\n",
       "      <th>SK_ID_PREV_pcb</th>\n",
       "      <th>SK_ID_CURR_pcb</th>\n",
       "      <th>MONTHS_BALANCE_pcb</th>\n",
       "      <th>CNT_INSTALMENT</th>\n",
       "      <th>CNT_INSTALMENT_FUTURE</th>\n",
       "      <th>NAME_CONTRACT_STATUS_pcb</th>\n",
       "      <th>SK_DPD_pcb</th>\n",
       "      <th>SK_DPD_DEF_pcb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-1908.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2415125</td>\n",
       "      <td>200227</td>\n",
       "      <td>-32</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100031</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>979992.0</td>\n",
       "      <td>27076.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-258.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2706181</td>\n",
       "      <td>135757</td>\n",
       "      <td>-38</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>100047</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>1193580.0</td>\n",
       "      <td>35028.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-546.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1940977</td>\n",
       "      <td>138382</td>\n",
       "      <td>-2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>100049</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>288873.0</td>\n",
       "      <td>16258.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2674796</td>\n",
       "      <td>384799</td>\n",
       "      <td>-10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>100096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>252000.0</td>\n",
       "      <td>14593.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2726442</td>\n",
       "      <td>245973</td>\n",
       "      <td>-7</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272760</th>\n",
       "      <td>416187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>1087366.5</td>\n",
       "      <td>31923.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2748910</td>\n",
       "      <td>235906</td>\n",
       "      <td>-53</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64909</th>\n",
       "      <td>175270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>1546020.0</td>\n",
       "      <td>40783.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-2251.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2607838</td>\n",
       "      <td>198900</td>\n",
       "      <td>-9</td>\n",
       "      <td>36.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114394</th>\n",
       "      <td>232658</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>11074.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-1027.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2272203</td>\n",
       "      <td>343209</td>\n",
       "      <td>-25</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223704</th>\n",
       "      <td>359104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>1125000.0</td>\n",
       "      <td>32895.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1671452</td>\n",
       "      <td>296280</td>\n",
       "      <td>-49</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138953</th>\n",
       "      <td>261122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>12375.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2687494</td>\n",
       "      <td>428318</td>\n",
       "      <td>-41</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49650 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  TARGET  NAME_CONTRACT_TYPE  CODE_GENDER  FLAG_OWN_CAR  \\\n",
       "0           100002       1                   0            1             0   \n",
       "26          100031       1                   0            0             0   \n",
       "40          100047       1                   0            1             0   \n",
       "42          100049       1                   0            0             0   \n",
       "81          100096       1                   0            0             0   \n",
       "...            ...     ...                 ...          ...           ...   \n",
       "272760      416187       0                   0            1             1   \n",
       "64909       175270       0                   0            0             1   \n",
       "114394      232658       0                   0            1             0   \n",
       "223704      359104       0                   0            0             0   \n",
       "138953      261122       0                   1            1             1   \n",
       "\n",
       "        FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
       "0                     1             0          202500.0    406597.5   \n",
       "26                    1             0          112500.0    979992.0   \n",
       "40                    1             0          202500.0   1193580.0   \n",
       "42                    0             0          135000.0    288873.0   \n",
       "81                    1             0           81000.0    252000.0   \n",
       "...                 ...           ...               ...         ...   \n",
       "272760                1             0          112500.0   1087366.5   \n",
       "64909                 1             0          450000.0   1546020.0   \n",
       "114394                1             1          121500.0    225000.0   \n",
       "223704                1             0          112500.0   1125000.0   \n",
       "138953                0             0           90000.0    247500.0   \n",
       "\n",
       "        AMT_ANNUITY  ...  DAYS_TERMINATION  NFLAG_INSURED_ON_APPROVAL  \\\n",
       "0           24700.5  ...           -1908.0                        0.0   \n",
       "26          27076.5  ...            -258.0                        1.0   \n",
       "40          35028.0  ...            -546.0                        1.0   \n",
       "42          16258.5  ...               NaN                        NaN   \n",
       "81          14593.5  ...               NaN                        NaN   \n",
       "...             ...  ...               ...                        ...   \n",
       "272760      31923.0  ...               NaN                        NaN   \n",
       "64909       40783.5  ...           -2251.0                        0.0   \n",
       "114394      11074.5  ...           -1027.0                        0.0   \n",
       "223704      32895.0  ...               NaN                        NaN   \n",
       "138953      12375.0  ...               NaN                        NaN   \n",
       "\n",
       "        SK_ID_PREV_pcb  SK_ID_CURR_pcb  MONTHS_BALANCE_pcb  CNT_INSTALMENT  \\\n",
       "0              2415125          200227                 -32            12.0   \n",
       "26             2706181          135757                 -38             6.0   \n",
       "40             1940977          138382                  -2            12.0   \n",
       "42             2674796          384799                 -10            36.0   \n",
       "81             2726442          245973                  -7            13.0   \n",
       "...                ...             ...                 ...             ...   \n",
       "272760         2748910          235906                 -53            30.0   \n",
       "64909          2607838          198900                  -9            36.0   \n",
       "114394         2272203          343209                 -25            10.0   \n",
       "223704         1671452          296280                 -49            12.0   \n",
       "138953         2687494          428318                 -41            18.0   \n",
       "\n",
       "        CNT_INSTALMENT_FUTURE  NAME_CONTRACT_STATUS_pcb  SK_DPD_pcb  \\\n",
       "0                        12.0                         0           0   \n",
       "26                        6.0                         0           0   \n",
       "40                        2.0                         0           0   \n",
       "42                       16.0                         0           0   \n",
       "81                        0.0                         2           0   \n",
       "...                       ...                       ...         ...   \n",
       "272760                    1.0                         0           0   \n",
       "64909                    21.0                         0           0   \n",
       "114394                    3.0                         0           0   \n",
       "223704                    2.0                         0           0   \n",
       "138953                    7.0                         0           0   \n",
       "\n",
       "        SK_DPD_DEF_pcb  \n",
       "0                    0  \n",
       "26                   0  \n",
       "40                   0  \n",
       "42                   0  \n",
       "81                   0  \n",
       "...                ...  \n",
       "272760               0  \n",
       "64909                0  \n",
       "114394               0  \n",
       "223704               0  \n",
       "138953               0  \n",
       "\n",
       "[49650 rows x 207 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1161fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "920786c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=range(1, 7), min_child_weight=11, missing=-999, n_estimators=range(3, 8), nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.2s\n",
      "[18:28:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.7s\n",
      "[18:28:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.1s\n",
      "[18:28:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=range(1, 7), min_child_weight=11, missing=-999, n_estimators=range(3, 8), nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.2s\n",
      "[18:28:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.7s\n",
      "[18:28:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.7s\n",
      "[18:28:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=range(1, 7), min_child_weight=11, missing=-999, n_estimators=range(3, 8), nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.2s\n",
      "[18:28:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.7s\n",
      "[18:28:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.1s\n",
      "[18:28:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=range(1, 7), min_child_weight=11, missing=-999, n_estimators=range(3, 8), nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.2s\n",
      "[18:28:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.7s\n",
      "[18:28:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.7s\n",
      "[18:28:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.4s\n",
      "[18:28:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=range(1, 7), min_child_weight=11, missing=-999, n_estimators=range(3, 8), nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.2s\n",
      "[18:28:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.7s\n",
      "[18:28:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=1, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.8s\n",
      "[18:28:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.1s\n",
      "[18:28:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.3s\n",
      "[18:28:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.5s\n",
      "[18:28:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.3s\n",
      "[18:28:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.8s\n",
      "[18:28:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.4s\n",
      "[18:28:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.3s\n",
      "[18:28:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.8s\n",
      "[18:28:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.0s\n",
      "[18:28:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.3s\n",
      "[18:28:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.0s\n",
      "[18:28:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.4s\n",
      "[18:28:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.4s\n",
      "[18:28:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.0s\n",
      "[18:28:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.3s\n",
      "[18:28:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.3s\n",
      "[18:28:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.7s\n",
      "[18:28:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.5s\n",
      "[18:28:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.1s\n",
      "[18:28:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=2, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   0.9s\n",
      "[18:28:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.3s\n",
      "[18:28:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.4s\n",
      "[18:28:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.8s\n",
      "[18:28:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.4s\n",
      "[18:28:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.7s\n",
      "[18:28:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.8s\n",
      "[18:28:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.4s\n",
      "[18:28:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.1s\n",
      "[18:28:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.4s\n",
      "[18:28:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.8s\n",
      "[18:28:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.8s\n",
      "[18:28:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.0s\n",
      "[18:28:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.5s\n",
      "[18:28:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.4s\n",
      "[18:28:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.3s\n",
      "[18:28:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.1s\n",
      "[18:28:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.5s\n",
      "[18:28:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.2s\n",
      "[18:28:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.8s\n",
      "[18:28:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.9s\n",
      "[18:28:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.2s\n",
      "[18:28:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.3s\n",
      "[18:28:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.9s\n",
      "[18:28:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.3s\n",
      "[18:28:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.8s\n",
      "[18:28:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.5s\n",
      "[18:28:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.8s\n",
      "[18:28:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.1s\n",
      "[18:28:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.1s\n",
      "[18:28:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.4s\n",
      "[18:28:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.4s\n",
      "[18:28:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.5s\n",
      "[18:28:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.0s\n",
      "[18:28:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.3s\n",
      "[18:28:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.7s\n",
      "[18:28:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.2s\n",
      "[18:28:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.8s\n",
      "[18:28:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.9s\n",
      "[18:28:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.4s\n",
      "[18:28:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=11, missing=-999, n_estimators=7, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.9s\n",
      "[18:28:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.6s\n",
      "[18:28:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=4, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   1.9s\n",
      "[18:28:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=5, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.1s\n",
      "[18:28:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=6, nthread=4, objective=binary:logistic, seed=1337, silent=1, subsample=0.8; total time=   2.8s\n",
      "[18:28:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andru/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:28:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[18:28:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1,\n",
       "                                     enable_categorical=False, gamma=0,\n",
       "                                     gpu_id=-1, importance_type=None,\n",
       "                                     interaction_constraints='',\n",
       "                                     learning_rate=0.300000012,\n",
       "                                     max_delta_step=0, max_depth=6,\n",
       "                                     min_child_weigh...\n",
       "                                     scale_pos_weight=1, subsample=1,\n",
       "                                     tree_method='exact', validate_parameters=1,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=5,\n",
       "             param_grid={'colsample_bytree': [0.7], 'learning_rate': [0.05],\n",
       "                         'max_depth': range(1, 7), 'min_child_weight': [11],\n",
       "                         'missing': [-999], 'n_estimators': range(3, 8),\n",
       "                         'nthread': [4], 'objective': ['binary:logistic'],\n",
       "                         'seed': [1337], 'silent': [1], 'subsample': [0.8]},\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'nthread':[4],\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05],\n",
    "              'max_depth': range(1, 7),\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': range(3,8),\n",
    "              'missing':[-999],\n",
    "              'seed': [1337]}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(model, parameters, n_jobs=5, \n",
    "                   cv=StratifiedKFold(n_splits=5, shuffle=True),\n",
    "                   scoring='roc_auc',\n",
    "                   verbose=2, refit=True)\n",
    "\n",
    "clf.fit(train_1.drop(target, axis=1), train_1[target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "504dd92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.66224499, 0.71892977, 0.78048882, 0.84588103, 0.88025627,\n",
       "        0.77139254, 0.88258176, 0.98155403, 1.1235806 , 1.17926841,\n",
       "        0.87364964, 1.10652065, 1.25857639, 1.47057433, 1.60815501,\n",
       "        1.08856688, 1.30723848, 1.63559833, 1.83993645, 2.4305512 ,\n",
       "        1.32007523, 1.72751637, 1.97278786, 2.14415712, 2.55757103,\n",
       "        1.44982572, 1.96283545, 2.11128435, 2.62360325, 2.89891081]),\n",
       " 'std_fit_time': array([0.02221718, 0.02558428, 0.03594242, 0.03570055, 0.03325041,\n",
       "        0.0361022 , 0.07433078, 0.04287862, 0.10601879, 0.04435179,\n",
       "        0.06078401, 0.08286941, 0.07045421, 0.07698871, 0.10311997,\n",
       "        0.08751746, 0.05355422, 0.08195888, 0.16309078, 0.16813131,\n",
       "        0.18979523, 0.03263787, 0.20421059, 0.15690695, 0.2624887 ,\n",
       "        0.11627625, 0.16001514, 0.08245214, 0.19288925, 0.21908936]),\n",
       " 'mean_score_time': array([0.03896122, 0.03738155, 0.04585795, 0.05064702, 0.04610353,\n",
       "        0.04689531, 0.05376954, 0.06228809, 0.05759311, 0.05421157,\n",
       "        0.05952516, 0.06764503, 0.05402279, 0.06099892, 0.05655131,\n",
       "        0.05657301, 0.06237803, 0.05141301, 0.08063674, 0.05110579,\n",
       "        0.05797105, 0.07038274, 0.06399755, 0.06592183, 0.05594811,\n",
       "        0.05588059, 0.04876108, 0.0575357 , 0.06935253, 0.03821578]),\n",
       " 'std_score_time': array([0.00810968, 0.00478212, 0.00575565, 0.0122953 , 0.00737763,\n",
       "        0.0129709 , 0.01453185, 0.01348294, 0.01006557, 0.00940064,\n",
       "        0.00508918, 0.01035651, 0.00401132, 0.0073636 , 0.01820303,\n",
       "        0.00640339, 0.01741797, 0.0119196 , 0.03553762, 0.0160149 ,\n",
       "        0.00621962, 0.02822669, 0.00476251, 0.01123964, 0.01299084,\n",
       "        0.01526319, 0.00909367, 0.00659762, 0.01296668, 0.01245744]),\n",
       " 'param_colsample_bytree': masked_array(data=[0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "                    0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "                    0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "                    0.05, 0.05, 0.05],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4,\n",
       "                    4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_child_weight': masked_array(data=[11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "                    11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "                    11, 11],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_missing': masked_array(data=[-999, -999, -999, -999, -999, -999, -999, -999, -999,\n",
       "                    -999, -999, -999, -999, -999, -999, -999, -999, -999,\n",
       "                    -999, -999, -999, -999, -999, -999, -999, -999, -999,\n",
       "                    -999, -999, -999],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[3, 4, 5, 6, 7, 3, 4, 5, 6, 7, 3, 4, 5, 6, 7, 3, 4, 5,\n",
       "                    6, 7, 3, 4, 5, 6, 7, 3, 4, 5, 6, 7],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_nthread': masked_array(data=[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_objective': masked_array(data=['binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic',\n",
       "                    'binary:logistic', 'binary:logistic'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_seed': masked_array(data=[1337, 1337, 1337, 1337, 1337, 1337, 1337, 1337, 1337,\n",
       "                    1337, 1337, 1337, 1337, 1337, 1337, 1337, 1337, 1337,\n",
       "                    1337, 1337, 1337, 1337, 1337, 1337, 1337, 1337, 1337,\n",
       "                    1337, 1337, 1337],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_silent': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_subsample': masked_array(data=[0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 1,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 3,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 1,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 4,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 1,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 5,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 1,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 6,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 1,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 7,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 3,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 4,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 5,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 6,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 7,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 3,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 4,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 5,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 6,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 7,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 3,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 4,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 5,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 6,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 7,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 3,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 4,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 5,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 6,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 7,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 3,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 4,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 5,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 6,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 11,\n",
       "   'missing': -999,\n",
       "   'n_estimators': 7,\n",
       "   'nthread': 4,\n",
       "   'objective': 'binary:logistic',\n",
       "   'seed': 1337,\n",
       "   'silent': 1,\n",
       "   'subsample': 0.8}],\n",
       " 'split0_test_score': array([0.65889285, 0.66305384, 0.66500198, 0.66715628, 0.67317955,\n",
       "        0.67426718, 0.68017577, 0.67967129, 0.69318797, 0.69672373,\n",
       "        0.68938114, 0.69732961, 0.69859224, 0.70781418, 0.71286567,\n",
       "        0.70138433, 0.71002135, 0.71103641, 0.71872538, 0.72308567,\n",
       "        0.70991283, 0.71807239, 0.71821481, 0.72505563, 0.72848179,\n",
       "        0.71460783, 0.72387192, 0.72403296, 0.72956873, 0.73302231]),\n",
       " 'split1_test_score': array([0.6724791 , 0.6744465 , 0.67494575, 0.68033447, 0.68190394,\n",
       "        0.69046968, 0.69361695, 0.69502871, 0.70565552, 0.71305688,\n",
       "        0.70438579, 0.70909028, 0.71062012, 0.71886202, 0.72289452,\n",
       "        0.71324261, 0.72023451, 0.71950313, 0.72597836, 0.73025485,\n",
       "        0.71779137, 0.72473601, 0.72404633, 0.73052106, 0.73372772,\n",
       "        0.71975492, 0.72685822, 0.72603889, 0.73222191, 0.73571806]),\n",
       " 'split2_test_score': array([0.66888528, 0.67314454, 0.67580972, 0.6810238 , 0.68332284,\n",
       "        0.68477039, 0.68986732, 0.69146195, 0.70450387, 0.71005518,\n",
       "        0.70028031, 0.70741795, 0.7084824 , 0.71740273, 0.72206925,\n",
       "        0.71295406, 0.7191315 , 0.71965089, 0.72734852, 0.73080693,\n",
       "        0.7190108 , 0.72579991, 0.72596956, 0.73215467, 0.73500295,\n",
       "        0.72373326, 0.72997103, 0.73024365, 0.73482971, 0.7364845 ]),\n",
       " 'split3_test_score': array([0.66200824, 0.66302366, 0.6641616 , 0.67186724, 0.67165017,\n",
       "        0.67489056, 0.68105826, 0.68077637, 0.69346911, 0.70077201,\n",
       "        0.69248248, 0.69882034, 0.69875696, 0.70743624, 0.71349189,\n",
       "        0.70112465, 0.70948275, 0.70922425, 0.71696131, 0.7218382 ,\n",
       "        0.71147322, 0.71847212, 0.71700485, 0.72460429, 0.72836395,\n",
       "        0.71578467, 0.72226196, 0.72053985, 0.72758916, 0.73094307]),\n",
       " 'split4_test_score': array([0.66273467, 0.66866809, 0.66768148, 0.6710991 , 0.67560237,\n",
       "        0.67628377, 0.68064338, 0.67755286, 0.69768304, 0.70270088,\n",
       "        0.69495561, 0.70168864, 0.70146534, 0.71113872, 0.71700143,\n",
       "        0.70666989, 0.71210686, 0.71246751, 0.71994152, 0.72471321,\n",
       "        0.71279719, 0.71859173, 0.71925373, 0.72541993, 0.73020408,\n",
       "        0.71808961, 0.7244698 , 0.72443313, 0.73022191, 0.733582  ]),\n",
       " 'mean_test_score': array([0.66500003, 0.66846733, 0.66952011, 0.67429618, 0.67713177,\n",
       "        0.68013632, 0.68507234, 0.68489824, 0.6988999 , 0.70466174,\n",
       "        0.69629706, 0.70286936, 0.70358341, 0.71253078, 0.71766455,\n",
       "        0.70707511, 0.7141954 , 0.71437644, 0.72179102, 0.72613977,\n",
       "        0.71419708, 0.72113443, 0.72089786, 0.72755112, 0.73115609,\n",
       "        0.71839406, 0.72548658, 0.7250577 , 0.73088628, 0.73394999]),\n",
       " 'std_test_score': array([0.00494797, 0.00482921, 0.00492959, 0.00545566, 0.0046714 ,\n",
       "        0.00640406, 0.00558045, 0.00698533, 0.00530365, 0.00602585,\n",
       "        0.00539396, 0.00464472, 0.0050241 , 0.00477408, 0.0041865 ,\n",
       "        0.00530202, 0.00457886, 0.00436916, 0.00411253, 0.00370357,\n",
       "        0.0035728 , 0.0033961 , 0.00348403, 0.00314536, 0.00273005,\n",
       "        0.00321236, 0.00268443, 0.00315303, 0.00246507, 0.00197926]),\n",
       " 'rank_test_score': array([30, 29, 28, 27, 26, 25, 23, 24, 21, 18, 22, 20, 19, 16, 12, 17, 15,\n",
       "        13,  8,  5, 14,  9, 10,  4,  2, 11,  6,  7,  3,  1], dtype=int32)}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e368d7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_fit_time\n",
      "std_fit_time\n",
      "mean_score_time\n",
      "std_score_time\n",
      "param_colsample_bytree\n",
      "param_learning_rate\n",
      "param_max_depth\n",
      "param_min_child_weight\n",
      "param_missing\n",
      "param_n_estimators\n",
      "param_nthread\n",
      "param_objective\n",
      "param_seed\n",
      "param_silent\n",
      "param_subsample\n",
      "params\n",
      "split0_test_score\n",
      "split1_test_score\n",
      "split2_test_score\n",
      "split3_test_score\n",
      "split4_test_score\n",
      "mean_test_score\n",
      "std_test_score\n",
      "rank_test_score\n"
     ]
    }
   ],
   "source": [
    "for i in clf.cv_results_.keys():\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf7cc4c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7339499882865862 \n",
      " {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 11, 'missing': -999, 'n_estimators': 7, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 1337, 'silent': 1, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "score, i = maxi(clf.cv_results_['mean_test_score'])\n",
    "params = clf.cv_results_['params'][i]\n",
    "print (score, \"\\n\", params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ed8bda",
   "metadata": {},
   "source": [
    "теперь RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e841388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(use_label_encoder=False)\n",
    "parameters = {'nthread':[4],\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.001, 0.05, 0.1, 0.2, 0,3],\n",
    "              'max_depth': range(1, 20),\n",
    "              'min_child_weight': np.arange(0.5, 20, 0.5),\n",
    "              'gamma': [0, 0.25, 0.5, 1.0],\n",
    "              'subsample': np.arange(0.4, 1, 0.1),\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [3,10, 20, 50, 100],\n",
    "              'missing':[-999],\n",
    "              'seed': [1337]}\n",
    "fit_params = {'eval_metric': 'mlogloss',\n",
    "              'early_stopping_rounds': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d9b07e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_clf = RandomizedSearchCV(model, parameters, n_iter=20,\n",
    "                            n_jobs=5, verbose=2,\n",
    "                            cv=StratifiedKFold(n_splits=5, shuffle=True),\n",
    "                            scoring='roc_auc', refit=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1cc63ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[19:50:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=3, max_depth=10, min_child_weight=5.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=   5.0s\n",
      "[19:50:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=3, max_depth=18, min_child_weight=15.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7999999999999999; total time=   8.0s\n",
      "[19:50:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0, max_depth=9, min_child_weight=13.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  24.2s\n",
      "[19:51:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=3, max_depth=13, min_child_weight=10.5, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=   4.6s\n",
      "[19:51:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0, max_depth=19, min_child_weight=5.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  44.0s\n",
      "[19:52:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=9, min_child_weight=18.0, missing=-999, n_estimators=20, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7999999999999999; total time=  10.8s\n",
      "[19:52:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.001, max_depth=4, min_child_weight=7.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=  23.8s\n",
      "[19:52:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=3, max_depth=9, min_child_weight=13.5, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=   2.2s\n",
      "[19:52:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=3, max_depth=9, min_child_weight=13.5, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=   2.3s\n",
      "[19:52:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=3, max_depth=9, min_child_weight=13.5, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=   1.8s\n",
      "[19:52:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.2, max_depth=18, min_child_weight=15.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  38.7s\n",
      "[19:53:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.05, max_depth=17, min_child_weight=15.0, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   3.5s\n",
      "[19:53:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.1, max_depth=12, min_child_weight=10.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time= 1.2min\n",
      "[19:54:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.001, max_depth=10, min_child_weight=15.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time=   6.4s\n",
      "[19:54:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=17, min_child_weight=2.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time= 1.1min\n",
      "[19:55:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=16, min_child_weight=10.0, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time= 1.5min\n",
      "[19:57:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=18, min_child_weight=8.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=  53.7s\n",
      "[19:58:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:50:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=3, max_depth=10, min_child_weight=5.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=   5.1s\n",
      "[19:50:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=3, max_depth=18, min_child_weight=15.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7999999999999999; total time=   7.7s\n",
      "[19:50:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0, max_depth=9, min_child_weight=13.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  26.5s\n",
      "[19:51:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=3, max_depth=13, min_child_weight=10.5, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=   5.2s\n",
      "[19:51:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0, max_depth=19, min_child_weight=5.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  44.5s\n",
      "[19:52:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=9, min_child_weight=18.0, missing=-999, n_estimators=20, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7999999999999999; total time=  13.1s\n",
      "[19:52:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.001, max_depth=4, min_child_weight=7.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=  23.8s\n",
      "[19:52:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=3, max_depth=9, min_child_weight=13.5, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=   2.3s\n",
      "[19:52:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.2, max_depth=18, min_child_weight=15.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  36.3s\n",
      "[19:53:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.05, max_depth=17, min_child_weight=15.0, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   2.6s\n",
      "[19:53:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.1, max_depth=12, min_child_weight=10.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time= 1.2min\n",
      "[19:54:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.001, max_depth=10, min_child_weight=15.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time=   5.7s\n",
      "[19:54:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=17, min_child_weight=2.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=  59.8s\n",
      "[19:55:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=16, min_child_weight=10.0, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time= 1.5min\n",
      "[19:57:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=18, min_child_weight=8.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=  52.9s\n",
      "[19:57:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=2.5, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   8.3s\n",
      "[19:58:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=2.5, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   8.2s\n",
      "[19:58:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:50:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=3, max_depth=10, min_child_weight=5.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=   4.6s\n",
      "[19:50:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=3, max_depth=18, min_child_weight=15.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7999999999999999; total time=   8.0s\n",
      "[19:50:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0, max_depth=9, min_child_weight=13.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  23.5s\n",
      "[19:51:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=3, max_depth=13, min_child_weight=10.5, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=   5.3s\n",
      "[19:51:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0, max_depth=19, min_child_weight=5.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  48.6s\n",
      "[19:52:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=9, min_child_weight=18.0, missing=-999, n_estimators=20, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7999999999999999; total time=  11.8s\n",
      "[19:52:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.001, max_depth=4, min_child_weight=7.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=  24.6s\n",
      "[19:52:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.2, max_depth=18, min_child_weight=15.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  34.3s\n",
      "[19:53:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.05, max_depth=17, min_child_weight=15.0, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   3.3s\n",
      "[19:53:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.05, max_depth=17, min_child_weight=15.0, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   2.8s\n",
      "[19:53:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.1, max_depth=12, min_child_weight=10.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time= 1.2min\n",
      "[19:54:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.001, max_depth=10, min_child_weight=15.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time=   7.4s\n",
      "[19:54:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=17, min_child_weight=2.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time= 1.0min\n",
      "[19:55:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=16, min_child_weight=10.0, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time= 1.4min\n",
      "[19:57:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=18, min_child_weight=8.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=  52.6s\n",
      "[19:57:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=2.5, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   8.5s\n",
      "[19:58:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=2.5, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   8.2s\n",
      "[19:58:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:50:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=3, max_depth=10, min_child_weight=5.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=   4.2s\n",
      "[19:50:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=3, max_depth=18, min_child_weight=15.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7999999999999999; total time=   7.5s\n",
      "[19:50:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0, max_depth=9, min_child_weight=13.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  25.1s\n",
      "[19:51:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=3, max_depth=13, min_child_weight=10.5, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=   4.5s\n",
      "[19:51:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=3, max_depth=13, min_child_weight=10.5, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=   4.9s\n",
      "[19:51:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0, max_depth=19, min_child_weight=5.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  46.9s\n",
      "[19:52:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=9, min_child_weight=18.0, missing=-999, n_estimators=20, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7999999999999999; total time=  12.4s\n",
      "[19:52:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.001, max_depth=4, min_child_weight=7.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=  24.0s\n",
      "[19:52:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.2, max_depth=18, min_child_weight=15.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  38.6s\n",
      "[19:53:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.1, max_depth=12, min_child_weight=10.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time= 1.2min\n",
      "[19:54:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.001, max_depth=10, min_child_weight=15.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time=   5.0s\n",
      "[19:54:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=17, min_child_weight=2.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time= 1.1min\n",
      "[19:55:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=16, min_child_weight=10.0, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time= 1.5min\n",
      "[19:57:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=18, min_child_weight=8.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=  52.5s\n",
      "[19:58:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=14, min_child_weight=11.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   9.1s\n",
      "[19:58:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.1, max_depth=19, min_child_weight=2.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time= 1.2min\n",
      "[19:59:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0, max_depth=13, min_child_weight=7.0, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.8999999999999999; total time=   3.9s\n",
      "[19:59:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:50:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=3, max_depth=10, min_child_weight=5.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=   5.5s\n",
      "[19:50:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=3, max_depth=18, min_child_weight=15.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7999999999999999; total time=   8.5s\n",
      "[19:50:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0, max_depth=9, min_child_weight=13.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  27.7s\n",
      "[19:51:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0, max_depth=19, min_child_weight=5.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  49.2s\n",
      "[19:52:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=9, min_child_weight=18.0, missing=-999, n_estimators=20, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7999999999999999; total time=  11.9s\n",
      "[19:52:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.001, max_depth=4, min_child_weight=7.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=  22.5s\n",
      "[19:52:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=3, max_depth=9, min_child_weight=13.5, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=   1.4s\n",
      "[19:52:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.2, max_depth=18, min_child_weight=15.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.4; total time=  37.1s\n",
      "[19:53:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.05, max_depth=17, min_child_weight=15.0, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   2.9s\n",
      "[19:53:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.1, max_depth=12, min_child_weight=10.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time= 1.1min\n",
      "[19:54:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.001, max_depth=10, min_child_weight=15.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time=   5.8s\n",
      "[19:54:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=17, min_child_weight=2.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time= 1.1min\n",
      "[19:55:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=16, min_child_weight=10.0, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.5; total time= 1.5min\n",
      "[19:57:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=18, min_child_weight=8.0, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time=  55.5s\n",
      "[19:58:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=2.5, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   8.1s\n",
      "[19:58:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=14, min_child_weight=11.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   8.2s\n",
      "[19:58:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.1, max_depth=19, min_child_weight=2.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time= 1.2min\n",
      "[19:59:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:00:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           enable_categorical=False, gamma=None,\n",
       "                                           gpu_id=None, importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=No...\n",
       "                                        'min_child_weight': array([ 0.5,  1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,  5. ,  5.5,\n",
       "        6. ,  6.5,  7. ,  7.5,  8. ,  8.5,  9. ,  9.5, 10. , 10.5, 11. ,\n",
       "       11.5, 12. , 12.5, 13. , 13.5, 14. , 14.5, 15. , 15.5, 16. , 16.5,\n",
       "       17. , 17.5, 18. , 18.5, 19. , 19.5]),\n",
       "                                        'missing': [-999],\n",
       "                                        'n_estimators': [3, 10, 20, 50, 100],\n",
       "                                        'nthread': [4],\n",
       "                                        'objective': ['binary:logistic'],\n",
       "                                        'seed': [1337],\n",
       "                                        'subsample': array([0.4, 0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "                   random_state=42, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_clf.fit(train_1.drop(target, axis=1), train_1[target])\n",
    "#            **, fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "25333a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7413391788846193 {'subsample': 0.7999999999999999, 'seed': 1337, 'objective': 'binary:logistic', 'nthread': 4, 'n_estimators': 20, 'missing': -999, 'min_child_weight': 18.0, 'max_depth': 9, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 0.7}\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0, max_depth=13, min_child_weight=7.0, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.8999999999999999; total time=   2.6s\n",
      "[19:59:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0, max_depth=13, min_child_weight=7.0, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.8999999999999999; total time=   3.7s\n",
      "[19:59:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0, max_depth=12, min_child_weight=10.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time= 1.3min\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0, max_depth=12, min_child_weight=10.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time= 1.3min\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=14, min_child_weight=11.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=   9.7s\n",
      "[19:58:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.1, max_depth=19, min_child_weight=2.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time= 1.1min\n",
      "[19:59:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0, max_depth=12, min_child_weight=10.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time= 1.3min\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=14, min_child_weight=11.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=  10.1s\n",
      "[19:58:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.1, max_depth=19, min_child_weight=2.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time= 1.2min\n",
      "[19:59:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0, max_depth=12, min_child_weight=10.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time= 1.3min\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=14, min_child_weight=11.0, missing=-999, n_estimators=10, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time=  10.2s\n",
      "[19:58:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0.1, max_depth=19, min_child_weight=2.5, missing=-999, n_estimators=50, nthread=4, objective=binary:logistic, seed=1337, subsample=0.7; total time= 1.1min\n",
      "[19:59:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0, max_depth=13, min_child_weight=7.0, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.8999999999999999; total time=   3.9s\n",
      "[19:59:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0, max_depth=13, min_child_weight=7.0, missing=-999, n_estimators=3, nthread=4, objective=binary:logistic, seed=1337, subsample=0.8999999999999999; total time=   3.5s\n",
      "[19:59:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.7, gamma=0.25, learning_rate=0, max_depth=12, min_child_weight=10.5, missing=-999, n_estimators=100, nthread=4, objective=binary:logistic, seed=1337, subsample=0.6; total time= 1.3min\n"
     ]
    }
   ],
   "source": [
    "print(rs_clf.best_score_, rs_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "93da62bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:13:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.7,\n",
       "              enable_categorical=False, gamma=0, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=9,\n",
       "              min_child_weight=18.0, missing=-999, monotone_constraints='()',\n",
       "              n_estimators=20, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
       "              predictor='auto', random_state=1337, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, seed=1337, subsample=0.7999999999999999,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, ...)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(use_label_encoder=False, **rs_clf.best_params_)\n",
    "model.fit(train_1.drop(target, axis=1), train_1[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "65eb0a10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIcAAAKrCAYAAABrz+3sAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjPklEQVR4nO3df6zldX7X8de7M0LVKlV2bAywHRSqmbVmrSPbxLZWSbdQorONrIKmJQZDG5dEo41OTVxX0j/AxJKY0ioGUqQqbKirkzAVTWlsNC1laLfdHTbEWUoDuLazQKhrZensvv3jHuzl7oU5M/f3fT8eyWTO9/v93Lmfc+793nPOc77f763uDgAAAAAzfdVOTwAAAACAnSMOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAx2cKcnsNZ73vOePnz48E5PAwAAAGDfeOaZZz7f3YfW27br4tDhw4dz6tSpnZ4GAAAAwL5RVb/2TtucVgYAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMNhScaiqbqiq56rqTFUdX2f7pVX16GL7U1V1eNW2P1lVP1dVp6vqU1X11Zs4fwAAAAA24LxxqKoOJLkvyY1JjiS5taqOrBl2e5LXuvuaJPcmuWfxsQeT/ESS7+/u9yX59iS/vWmzBwAAAGBDljly6LokZ7r7+e5+M8kjSY6tGXMsyUOL248lub6qKskHk/xKd/9yknT3K939pc2ZOgAAAAAbtUwcuiLJi6uWX1qsW3dMd59L8nqSy5N8Q5Kuqieq6her6u+v9wmq6o6qOlVVp86ePXuh9wEAAACAi7TVF6Q+mORbkvz1xd/fXVXXrx3U3fd399HuPnro0KEtnhIAAAAAb1kmDr2c5KpVy1cu1q07ZnGdocuSvJKVo4x+trs/392/leRkkm/a6KQBAAAA2BzLxKGnk1xbVVdX1SVJbklyYs2YE0luW9y+OcmT3d1JnkjyjVX1exbR6M8leXZzpg4AAADARh0834DuPldVd2Yl9BxI8mB3n66qu5Kc6u4TSR5I8nBVnUnyalYCUrr7tar64awEpk5ysrsf36L7AgAAAMAFqpUDfHaPo0eP9qlTp3Z6GgAAAAD7RlU9091H19u21RekBgAAAGAXO+9pZQDb7fDxt599+sLdN+3QTAAAAPY/Rw4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMtlQcqqobquq5qjpTVcfX2X5pVT262P5UVR1erD9cVf+3qj65+PMvNnn+AAAAAGzAwfMNqKoDSe5L8h1JXkrydFWd6O5nVw27Pclr3X1NVd2S5J4kf3Wx7bPd/f7NnTYAAAAAm2GZI4euS3Kmu5/v7jeTPJLk2Joxx5I8tLj9WJLrq6o2b5oAAAAAbIVl4tAVSV5ctfzSYt26Y7r7XJLXk1y+2HZ1Vf1SVf3XqvrWDc4XAAAAgE103tPKNuhzSd7b3a9U1Z9O8h+q6n3d/ZurB1XVHUnuSJL3vve9WzwlAAAAAN6yzJFDLye5atXylYt1646pqoNJLkvySnd/sbtfSZLufibJZ5N8w9pP0N33d/fR7j566NChC78XAAAAAFyUZeLQ00muraqrq+qSJLckObFmzIkkty1u35zkye7uqjq0uKB1quqPJLk2yfObM3UAAAAANuq8p5V197mqujPJE0kOJHmwu09X1V1JTnX3iSQPJHm4qs4keTUrASlJvi3JXVX120m+nOT7u/vVrbgjAAAAAFy4pa451N0nk5xcs+6jq26/keTD63zcTyb5yQ3OEQAAAIAtssxpZQAAAADsU+IQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYAd3egLAbIePP/625RfuvmmHZgIAADCTI4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABlsqDlXVDVX1XFWdqarj62y/tKoeXWx/qqoOr9n+3qr6QlX9wCbNGwAAAIBNcN44VFUHktyX5MYkR5LcWlVH1gy7Pclr3X1NknuT3LNm+w8n+amNTxcAAACAzbTMkUPXJTnT3c9395tJHklybM2YY0keWtx+LMn1VVVJUlUfSvKrSU5vyowBAAAA2DTLxKErkry4avmlxbp1x3T3uSSvJ7m8qr4myT9I8k/e7RNU1R1VdaqqTp09e3bZuQMAAACwQVt9QeqPJbm3u7/wboO6+/7uPtrdRw8dOrTFUwIAAADgLQeXGPNykqtWLV+5WLfemJeq6mCSy5K8kuQDSW6uqn+a5GuTfLmq3ujuH9noxAEAAADYuGXi0NNJrq2qq7MSgW5J8tfWjDmR5LYkP5fk5iRPdncn+da3BlTVx5J8QRgCAAAA2D3OG4e6+1xV3ZnkiSQHkjzY3aer6q4kp7r7RJIHkjxcVWeSvJqVgAQAAADALrfMkUPp7pNJTq5Z99FVt99I8uHz/Bsfu4j5AQAAALCFtvqC1AAAAADsYuIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBgS8Whqrqhqp6rqjNVdXyd7ZdW1aOL7U9V1eHF+uuq6pOLP79cVd+9yfMHAAAAYAPOG4eq6kCS+5LcmORIklur6siaYbcnea27r0lyb5J7Fus/neRod78/yQ1J/mVVHdykuQMAAACwQcscOXRdkjPd/Xx3v5nkkSTH1ow5luShxe3HklxfVdXdv9Xd5xbrvzpJb8akAQAAANgcy8ShK5K8uGr5pcW6dccsYtDrSS5Pkqr6QFWdTvKpJN+/Khb9f1V1R1WdqqpTZ8+evfB7AQAAAMBF2fILUnf3U939viR/JskPVtVXrzPm/u4+2t1HDx06tNVTAgAAAGBhmTj0cpKrVi1fuVi37pjFNYUuS/LK6gHd/ZkkX0jyJy52sgAAAABsrmXi0NNJrq2qq6vqkiS3JDmxZsyJJLctbt+c5Mnu7sXHHEySqvr6JH88yQubMnMAAAAANuy8vzmsu89V1Z1JnkhyIMmD3X26qu5Kcqq7TyR5IMnDVXUmyatZCUhJ8i1JjlfVbyf5cpK/1d2f34o7AgAAAMCFW+rXynf3ySQn16z76KrbbyT58Dof93CShzc4RwAAAAC2yJZfkBoAAACA3UscAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABjs4E5PgP3h8PHH37b8wt037dBMAAAAgAvhyCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMEO7vQE2HsOH3/8bcsv3H3TDs0EAAAA2ChHDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADLZUHKqqG6rquao6U1XH19l+aVU9utj+VFUdXqz/jqp6pqo+tfj7L2zy/AEAAADYgPPGoao6kOS+JDcmOZLk1qo6smbY7Ule6+5rktyb5J7F+s8n+Yvd/Y1Jbkvy8GZNHAAAAICNW+bIoeuSnOnu57v7zSSPJDm2ZsyxJA8tbj+W5Pqqqu7+pe7+n4v1p5P87qq6dDMmDgAAAMDGLROHrkjy4qrllxbr1h3T3eeSvJ7k8jVj/nKSX+zuL679BFV1R1WdqqpTZ8+eXXbuAAAAAGzQtlyQuqrel5VTzb5vve3dfX93H+3uo4cOHdqOKQEAAACQ5eLQy0muWrV85WLdumOq6mCSy5K8sli+Msknknxvd392oxMGAAAAYPMsE4eeTnJtVV1dVZckuSXJiTVjTmTlgtNJcnOSJ7u7q+prkzye5Hh3//dNmjMAAAAAm+S8cWhxDaE7kzyR5DNJPt7dp6vqrqr6S4thDyS5vKrOJPm7Sd76dfd3JrkmyUer6pOLP39o0+8FAAAAABfl4DKDuvtkkpNr1n101e03knx4nY/7oSQ/tME5AgAAALBFtuWC1AAAAADsTuIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYAd3egLAHIePP/625RfuvmmHZgIAAMBbHDkEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMNjBnZ4AyeHjj79t+YW7b9qhmQAAAADTOHIIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYLCDOz0B4CsdPv7425ZfuPumHZoJAAAA+50jhwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGE4cAAAAABhOHAAAAAAYThwAAAAAGO7jTE4D1HD7++NuWX7j7ph2aCQAAAOxvjhwCAAAAGEwcAgAAABjMaWUAwJ7j9GMAgM3jyCEAAACAwZaKQ1V1Q1U9V1Vnqur4OtsvrapHF9ufqqrDi/WXV9XPVNUXqupHNnnuAAAAAGzQeeNQVR1Icl+SG5McSXJrVR1ZM+z2JK919zVJ7k1yz2L9G0n+UZIf2LQZAwAAALBplrnm0HVJznT380lSVY8kOZbk2VVjjiX52OL2Y0l+pKqqu/9Pkv9WVdds3pT3NtdIuHgeOwAAANh8y5xWdkWSF1ctv7RYt+6Y7j6X5PUkly87iaq6o6pOVdWps2fPLvthAAAAAGzQrrggdXff391Hu/vooUOHdno6AAAAAGMsc1rZy0muWrV85WLdemNeqqqDSS5L8sqmzJBt47QtAAAAmGeZI4eeTnJtVV1dVZckuSXJiTVjTiS5bXH75iRPdndv3jQBAAAA2ArnPXKou89V1Z1JnkhyIMmD3X26qu5Kcqq7TyR5IMnDVXUmyatZCUhJkqp6IcnvT3JJVX0oyQe7+9kAe8LqI8ocTQYAALD/LHNaWbr7ZJKTa9Z9dNXtN5J8+B0+9vAG5gcAAADAFloqDgEAXAjXsQMA2Dt2xW8rAwAAAGBniEMAAAAAgzmtDPYIp2gAAACwFRw5BAAAADCYOAQAAAAwmNPKYIc5XQwAAICd5MghAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMFckHoPceFiAAAAYLM5cggAAABgMEcODeGoIwAAAGA94tAuJeYAAAAA20EcAgB2zOr/DPEfIQAAO0McYgRHYgHA9vG8CwB7izgEAMCeJ0gBwMXz28oAAAAABnPkEACwazj6AwBg+zlyCAAAAGAwRw4Be4KjCQAAALaGI4cAAAAABnPkEMAe4Mgp2H72OwBgCnFoKC94AQAAgMRpZQAAAACjiUMAAAAAgzmtDGCfcxopAADwbhw5BAAAADCYI4fYVo5gAAAA9hrvY9jvxCF4F54EYGvt1D5m3wYAgN8hDu1x3uDAxbHv7F6+NgAAsL3EIbaMN3gAAACw+4lDACQRdAEAknmviabdX9YnDgEM5EUAAADwFr/KHgAAAGAwRw4BALBrOLIRALafOMS+s5tfVO7mucF+sJF9bDv2z9WfYy/s/35mAQDMIA4BsGEiwmy+/sBqfiYA7D3iEMAF2mtHf7C5vOkB2F5+7sL52U/YKHEI2LOWfRL0ZHnx9sNjtx/uAwAAbCVxCIBtIdJ8JY8JzOZnAAC7hTgEm8CLu6/kMdl6HmPW8j0BAMDFEIcAdhlv8HcPXwuAvc11AgGWIw7tQ5v5ZsYbI5bh+wT2PvsxMIGfdRfPY7ccjxN7lTgEAACDbeTNrDfCAPuDOASwsB9e4O6H+8BX8nWF3cG+CPuT0w/Pz8+//U8cYk/zQ4rdatnvTd/DF89jt/f4mrEf+b5ejscJWM3PhN1HHNpCvuFh+232frfMv2dfB2CzeE7ZHXwdLp7Hbrbt+Pr7Htsa4hAAALuaUz7YDbwhvXgeO9j9xCGAbeKFEQDbyfPO7rFfvxZ78X7txTlfrEn3lY0Th9hxfmgBwEy7+TXAbp4b+P7cn6Z/Xaff/50mDgEAwBbb7utwuM4HG7Gbvta7aS67hceErSAOAQAwhjdV+4OvI+wdG9lf/Qbg7SMOARfED14A2Lu80QJgPeIQAOwi3pABsJXWnn7oeWdneNzZbcQhAGAUL8iB/cjPtt1rv35t9uv9mkocAgAAdoXtuDYJAF9JHAIAYE8RAQBgc4lDsM94wQwAAPuD1/ZsF3EIAAAA2FeEtQsjDgEAsOW8SAeA3UscAgAAgAskerOfiEMAAAAwgKDFOxGHAAAA9iEhAFjWV+30BAAAAADYOY4cgj3M/wYBAMD6vFaG5YlDAFwQL7QAAGB/cVoZAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBgB3d6AgAAwIU5fPzxty2/cPdNOzQTAPYDRw4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADLZUHKqqG6rquao6U1XH19l+aVU9utj+VFUdXrXtBxfrn6uq79zEuQMAAACwQeeNQ1V1IMl9SW5MciTJrVV1ZM2w25O81t3XJLk3yT2Ljz2S5JYk70tyQ5IfXfx7AAAAAOwCyxw5dF2SM939fHe/meSRJMfWjDmW5KHF7ceSXF9VtVj/SHd/sbt/NcmZxb8HAAAAwC5Q3f3uA6puTnJDd//NxfL3JPlAd9+5asynF2NeWix/NskHknwsyc93908s1j+Q5Ke6+7E1n+OOJHcsFv9Ykuc2ftd2lfck+fxOTwLYdPZt2H/s17D/2K9hf7JvX7iv7+5D6204uN0zWU9335/k/p2ex1apqlPdfXSn5wFsLvs27D/2a9h/7NewP9m3N9cyp5W9nOSqVctXLtatO6aqDia5LMkrS34sAAAAADtkmTj0dJJrq+rqqrokKxeYPrFmzIkkty1u35zkyV45X+1EklsWv83s6iTXJvmFzZk6AAAAABt13tPKuvtcVd2Z5IkkB5I82N2nq+quJKe6+0SSB5I8XFVnkryalYCUxbiPJ3k2ybkkH+nuL23RfdnN9u0pczCcfRv2H/s17D/2a9if7Nub6LwXpAYAAABg/1rmtDIAAAAA9ilxCAAAAGAwcWiLVdUNVfVcVZ2pquM7PR/g4lTVC1X1qar6ZFWdWqz7g1X1X6rqfyz+/gM7PU/g3VXVg1X1G1X16VXr1t2Xa8U/XzyH/0pVfdPOzRx4J++wX3+sql5ePG9/sqq+a9W2H1zs189V1XfuzKyBd1NVV1XVz1TVs1V1uqr+9mK95+wtIg5toao6kOS+JDcmOZLk1qo6srOzAjbgz3f3+7v76GL5eJKf7u5rk/z0YhnY3X48yQ1r1r3TvnxjVn7T6rVJ7kjyY9s0R+DC/Hi+cr9OknsXz9vv7+6TSbJ4LX5LkvctPuZHF6/Zgd3lXJK/191Hknxzko8s9l/P2VtEHNpa1yU5093Pd/ebSR5JcmyH5wRsnmNJHlrcfijJh3ZuKsAyuvtns/KbVVd7p335WJJ/3St+PsnXVtUf3paJAkt7h/36nRxL8kh3f7G7fzXJmay8Zgd2ke7+XHf/4uL2/07ymSRXxHP2lhGHttYVSV5ctfzSYh2w93SS/1xVz1TVHYt1X9fdn1vc/l9Jvm5npgZs0Dvty57HYW+7c3F6yYOrTv22X8MeU1WHk/ypJE/Fc/aWEYcAlvMt3f1NWTlk9SNV9W2rN3Z3ZyUgAXuYfRn2jR9L8keTvD/J55L8sx2dDXBRquprkvxkkr/T3b+5epvn7M0lDm2tl5NctWr5ysU6YI/p7pcXf/9Gkk9k5RD0X3/rcNXF37+xczMENuCd9mXP47BHdfevd/eXuvvLSf5VfufUMfs17BFV9buyEob+TXf/+8Vqz9lbRBzaWk8nubaqrq6qS7Jy8bsTOzwn4AJV1e+tqt/31u0kH0zy6azsz7ctht2W5D/uzAyBDXqnfflEku9d/AaUb07y+qpD2YFdbM21Rr47K8/bycp+fUtVXVpVV2fl4rW/sN3zA95dVVWSB5J8prt/eNUmz9lb5OBOT2A/6+5zVXVnkieSHEjyYHef3uFpARfu65J8YuU5KgeT/Nvu/k9V9XSSj1fV7Ul+Lclf2cE5Akuoqn+X5NuTvKeqXkryj5PcnfX35ZNJvisrF6z9rSR/Y9snDJzXO+zX315V78/KKScvJPm+JOnu01X18STPZuW3IX2ku7+0A9MG3t2fTfI9ST5VVZ9crPuH8Zy9ZWrlND0AAAAAJnJaGQAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg4hAAAADAYOIQAAAAwGDiEAAAAMBg/w+Q77GunsjvkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance = model.feature_importances_\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a3efcc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SK_ID_CURR': 0.004825197,\n",
       " 'TARGET': 0.010096483,\n",
       " 'NAME_CONTRACT_TYPE': 0.016651189,\n",
       " 'CODE_GENDER': 0.008081167,\n",
       " 'FLAG_OWN_CAR': 0.008401337,\n",
       " 'FLAG_OWN_REALTY': 0.006470433,\n",
       " 'CNT_CHILDREN': 0.0052282605,\n",
       " 'AMT_INCOME_TOTAL': 0.008170746,\n",
       " 'AMT_CREDIT': 0.0071084434,\n",
       " 'AMT_ANNUITY': 0.009830746,\n",
       " 'AMT_GOODS_PRICE': 0.005213839,\n",
       " 'NAME_TYPE_SUITE': 0.020937376,\n",
       " 'NAME_INCOME_TYPE': 0.021782735,\n",
       " 'NAME_EDUCATION_TYPE': 0.0063847415,\n",
       " 'NAME_FAMILY_STATUS': 0.006630727,\n",
       " 'NAME_HOUSING_TYPE': 0.0045953235,\n",
       " 'REGION_POPULATION_RELATIVE': 0.010739932,\n",
       " 'DAYS_BIRTH': 0.010087177,\n",
       " 'DAYS_EMPLOYED': 0.0049039647,\n",
       " 'DAYS_REGISTRATION': 0.0058860914,\n",
       " 'DAYS_ID_PUBLISH': 0.007945657,\n",
       " 'OWN_CAR_AGE': 0.0,\n",
       " 'FLAG_MOBIL': 0.0,\n",
       " 'FLAG_EMP_PHONE': 0.006550237,\n",
       " 'FLAG_WORK_PHONE': 0.0,\n",
       " 'FLAG_CONT_MOBILE': 0.0053799674,\n",
       " 'FLAG_PHONE': 0.0,\n",
       " 'FLAG_EMAIL': 0.005869784,\n",
       " 'OCCUPATION_TYPE': 0.008855419,\n",
       " 'CNT_FAM_MEMBERS': 0.011563012,\n",
       " 'REGION_RATING_CLIENT': 0.009184831,\n",
       " 'REGION_RATING_CLIENT_W_CITY': 0.0031504666,\n",
       " 'WEEKDAY_APPR_PROCESS_START': 0.0038030315,\n",
       " 'HOUR_APPR_PROCESS_START': 0.0,\n",
       " 'REG_REGION_NOT_LIVE_REGION': 0.0,\n",
       " 'REG_REGION_NOT_WORK_REGION': 0.0,\n",
       " 'LIVE_REGION_NOT_WORK_REGION': 0.0096574705,\n",
       " 'REG_CITY_NOT_LIVE_CITY': 0.004319267,\n",
       " 'REG_CITY_NOT_WORK_CITY': 0.005275952,\n",
       " 'LIVE_CITY_NOT_WORK_CITY': 0.0054060463,\n",
       " 'ORGANIZATION_TYPE': 0.018504577,\n",
       " 'EXT_SOURCE_1': 0.04794853,\n",
       " 'EXT_SOURCE_2': 0.05936004,\n",
       " 'EXT_SOURCE_3': 0.007390454,\n",
       " 'APARTMENTS_AVG': 0.0055742725,\n",
       " 'BASEMENTAREA_AVG': 0.0048139733,\n",
       " 'YEARS_BEGINEXPLUATATION_AVG': 0.0055924584,\n",
       " 'YEARS_BUILD_AVG': 0.0064836126,\n",
       " 'COMMONAREA_AVG': 0.00501237,\n",
       " 'ELEVATORS_AVG': 0.0048869806,\n",
       " 'ENTRANCES_AVG': 0.005721653,\n",
       " 'FLOORSMAX_AVG': 0.0048633358,\n",
       " 'FLOORSMIN_AVG': 0.0049801795,\n",
       " 'LANDAREA_AVG': 0.004648765,\n",
       " 'LIVINGAPARTMENTS_AVG': 0.004916187,\n",
       " 'LIVINGAREA_AVG': 0.005335049,\n",
       " 'NONLIVINGAPARTMENTS_AVG': 0.007199407,\n",
       " 'NONLIVINGAREA_AVG': 0.00541269,\n",
       " 'APARTMENTS_MODE': 0.005086564,\n",
       " 'BASEMENTAREA_MODE': 0.006824554,\n",
       " 'YEARS_BEGINEXPLUATATION_MODE': 0.006217085,\n",
       " 'YEARS_BUILD_MODE': 0.00624943,\n",
       " 'COMMONAREA_MODE': 0.0056259236,\n",
       " 'ELEVATORS_MODE': 0.0030012073,\n",
       " 'ENTRANCES_MODE': 0.00579774,\n",
       " 'FLOORSMAX_MODE': 0.0,\n",
       " 'FLOORSMIN_MODE': 0.0054930947,\n",
       " 'LANDAREA_MODE': 0.0065704873,\n",
       " 'LIVINGAPARTMENTS_MODE': 0.006463276,\n",
       " 'LIVINGAREA_MODE': 0.0,\n",
       " 'NONLIVINGAPARTMENTS_MODE': 0.0049075745,\n",
       " 'NONLIVINGAREA_MODE': 0.005893599,\n",
       " 'APARTMENTS_MEDI': 0.005601326,\n",
       " 'BASEMENTAREA_MEDI': 0.0065705283,\n",
       " 'YEARS_BEGINEXPLUATATION_MEDI': 0.0059206695,\n",
       " 'YEARS_BUILD_MEDI': 0.0053410023,\n",
       " 'COMMONAREA_MEDI': 0.0057478943,\n",
       " 'ELEVATORS_MEDI': 0.0,\n",
       " 'ENTRANCES_MEDI': 0.0,\n",
       " 'FLOORSMAX_MEDI': 0.0058686878,\n",
       " 'FLOORSMIN_MEDI': 0.005527812,\n",
       " 'LANDAREA_MEDI': 0.0042015077,\n",
       " 'LIVINGAPARTMENTS_MEDI': 0.0050248723,\n",
       " 'LIVINGAREA_MEDI': 0.0,\n",
       " 'NONLIVINGAPARTMENTS_MEDI': 0.005460094,\n",
       " 'NONLIVINGAREA_MEDI': 0.0,\n",
       " 'FONDKAPREMONT_MODE': 0.0,\n",
       " 'HOUSETYPE_MODE': 0.0052742385,\n",
       " 'TOTALAREA_MODE': 0.005895642,\n",
       " 'WALLSMATERIAL_MODE': 0.0,\n",
       " 'EMERGENCYSTATE_MODE': 0.0058097923,\n",
       " 'OBS_30_CNT_SOCIAL_CIRCLE': 0.009481212,\n",
       " 'DEF_30_CNT_SOCIAL_CIRCLE': 0.0049930597,\n",
       " 'OBS_60_CNT_SOCIAL_CIRCLE': 0.008046216,\n",
       " 'DEF_60_CNT_SOCIAL_CIRCLE': 0.0076330495,\n",
       " 'DAYS_LAST_PHONE_CHANGE': 0.0,\n",
       " 'FLAG_DOCUMENT_2': 0.010454108,\n",
       " 'FLAG_DOCUMENT_3': 0.0,\n",
       " 'FLAG_DOCUMENT_4': 0.0,\n",
       " 'FLAG_DOCUMENT_5': 0.004116129,\n",
       " 'FLAG_DOCUMENT_6': 0.0,\n",
       " 'FLAG_DOCUMENT_7': 0.0072570597,\n",
       " 'FLAG_DOCUMENT_8': 0.0,\n",
       " 'FLAG_DOCUMENT_9': 0.0,\n",
       " 'FLAG_DOCUMENT_10': 0.0,\n",
       " 'FLAG_DOCUMENT_11': 0.0,\n",
       " 'FLAG_DOCUMENT_12': 0.0,\n",
       " 'FLAG_DOCUMENT_13': 0.0,\n",
       " 'FLAG_DOCUMENT_14': 0.0,\n",
       " 'FLAG_DOCUMENT_15': 0.0,\n",
       " 'FLAG_DOCUMENT_16': 0.0,\n",
       " 'FLAG_DOCUMENT_17': 0.0,\n",
       " 'FLAG_DOCUMENT_18': 0.0,\n",
       " 'FLAG_DOCUMENT_19': 0.0,\n",
       " 'FLAG_DOCUMENT_20': 0.0,\n",
       " 'FLAG_DOCUMENT_21': 0.0,\n",
       " 'AMT_REQ_CREDIT_BUREAU_HOUR': 0.0,\n",
       " 'AMT_REQ_CREDIT_BUREAU_DAY': 0.0078677535,\n",
       " 'AMT_REQ_CREDIT_BUREAU_WEEK': 0.003623209,\n",
       " 'AMT_REQ_CREDIT_BUREAU_MON': 0.0045784838,\n",
       " 'AMT_REQ_CREDIT_BUREAU_QRT': 0.006026327,\n",
       " 'AMT_REQ_CREDIT_BUREAU_YEAR': 0.004752465,\n",
       " 'SK_ID_CURR_b': 0.003921871,\n",
       " 'SK_ID_BUREAU': 0.0077774394,\n",
       " 'CREDIT_ACTIVE': 0.0,\n",
       " 'CREDIT_CURRENCY': 0.0043851538,\n",
       " 'DAYS_CREDIT': 0.0,\n",
       " 'CREDIT_DAY_OVERDUE': 0.0045966264,\n",
       " 'DAYS_CREDIT_ENDDATE': 0.0050396817,\n",
       " 'DAYS_ENDDATE_FACT': 0.0049691964,\n",
       " 'AMT_CREDIT_MAX_OVERDUE': 0.0,\n",
       " 'CNT_CREDIT_PROLONG': 0.004490666,\n",
       " 'AMT_CREDIT_SUM': 0.0054797097,\n",
       " 'AMT_CREDIT_SUM_DEBT': 0.0048285136,\n",
       " 'AMT_CREDIT_SUM_LIMIT': 0.0,\n",
       " 'AMT_CREDIT_SUM_OVERDUE': 0.002175264,\n",
       " 'CREDIT_TYPE': 0.0044848584,\n",
       " 'DAYS_CREDIT_UPDATE': 0.0046440302,\n",
       " 'AMT_ANNUITY_b': 0.0042946236,\n",
       " 'SK_ID_PREV': 0.005161193,\n",
       " 'SK_ID_CURR_ccb': 0.0043043434,\n",
       " 'MONTHS_BALANCE': 0.0045002224,\n",
       " 'AMT_BALANCE': 0.0051501915,\n",
       " 'AMT_CREDIT_LIMIT_ACTUAL': 0.00580706,\n",
       " 'AMT_DRAWINGS_ATM_CURRENT': 0.0049133175,\n",
       " 'AMT_DRAWINGS_CURRENT': 0.0,\n",
       " 'AMT_DRAWINGS_OTHER_CURRENT': 0.0039897584,\n",
       " 'AMT_DRAWINGS_POS_CURRENT': 0.0057477006,\n",
       " 'AMT_INST_MIN_REGULARITY': 0.004385153,\n",
       " 'AMT_PAYMENT_CURRENT': 0.0039819893,\n",
       " 'AMT_PAYMENT_TOTAL_CURRENT': 0.00529712,\n",
       " 'AMT_RECEIVABLE_PRINCIPAL': 0.00528145,\n",
       " 'AMT_RECIVABLE': 0.0,\n",
       " 'AMT_TOTAL_RECEIVABLE': 0.004872755,\n",
       " 'CNT_DRAWINGS_ATM_CURRENT': 0.004732489,\n",
       " 'CNT_DRAWINGS_CURRENT': 0.0,\n",
       " 'CNT_DRAWINGS_OTHER_CURRENT': 0.0,\n",
       " 'CNT_DRAWINGS_POS_CURRENT': 0.0046636416,\n",
       " 'CNT_INSTALMENT_MATURE_CUM': 0.0,\n",
       " 'NAME_CONTRACT_STATUS': 0.0,\n",
       " 'SK_DPD': 0.0,\n",
       " 'SK_DPD_DEF': 0.004566329,\n",
       " 'SK_ID_PREV_pa': 0.004089639,\n",
       " 'SK_ID_CURR_pa': 0.003284131,\n",
       " 'NAME_CONTRACT_TYPE_pa': 0.0041737286,\n",
       " 'AMT_ANNUITY_pa': 0.0041397796,\n",
       " 'AMT_APPLICATION': 0.0044690687,\n",
       " 'AMT_CREDIT_pa': 0.005202022,\n",
       " 'AMT_DOWN_PAYMENT': 0.004657572,\n",
       " 'AMT_GOODS_PRICE_pa': 0.004810411,\n",
       " 'WEEKDAY_APPR_PROCESS_START_pa': 0.0047138464,\n",
       " 'HOUR_APPR_PROCESS_START_pa': 0.0,\n",
       " 'FLAG_LAST_APPL_PER_CONTRACT': 0.0,\n",
       " 'NFLAG_LAST_APPL_IN_DAY': 0.00446967,\n",
       " 'RATE_DOWN_PAYMENT': 0.0,\n",
       " 'RATE_INTEREST_PRIMARY': 0.0,\n",
       " 'RATE_INTEREST_PRIVILEGED': 0.003135316,\n",
       " 'NAME_CASH_LOAN_PURPOSE': 0.0046609193,\n",
       " 'NAME_CONTRACT_STATUS_pa': 0.005075613,\n",
       " 'DAYS_DECISION': 0.006260422,\n",
       " 'NAME_PAYMENT_TYPE': 0.0066347998,\n",
       " 'CODE_REJECT_REASON': 0.0034850764,\n",
       " 'NAME_TYPE_SUITE_pa': 0.005212035,\n",
       " 'NAME_CLIENT_TYPE': 0.004068834,\n",
       " 'NAME_GOODS_CATEGORY': 0.004155001,\n",
       " 'NAME_PORTFOLIO': 0.004580474,\n",
       " 'NAME_PRODUCT_TYPE': 0.003842935,\n",
       " 'CHANNEL_TYPE': 0.0044563063,\n",
       " 'SELLERPLACE_AREA': 0.0057400325,\n",
       " 'NAME_SELLER_INDUSTRY': 0.0046721655,\n",
       " 'CNT_PAYMENT': 0.003458836,\n",
       " 'NAME_YIELD_GROUP': 0.0062530166,\n",
       " 'PRODUCT_COMBINATION': 0.0,\n",
       " 'DAYS_FIRST_DRAWING': 0.0050885435,\n",
       " 'DAYS_FIRST_DUE': 0.00404222,\n",
       " 'DAYS_LAST_DUE_1ST_VERSION': 0.004810958,\n",
       " 'DAYS_LAST_DUE': 0.004396479,\n",
       " 'DAYS_TERMINATION': 0.0049249944,\n",
       " 'NFLAG_INSURED_ON_APPROVAL': 0.0045225434,\n",
       " 'SK_ID_PREV_pcb': 0.0043526688,\n",
       " 'SK_ID_CURR_pcb': 0.0048163333,\n",
       " 'MONTHS_BALANCE_pcb': 0.0043734666,\n",
       " 'CNT_INSTALMENT': 0.0036925587,\n",
       " 'CNT_INSTALMENT_FUTURE': 0.0,\n",
       " 'NAME_CONTRACT_STATUS_pcb': 0.0,\n",
       " 'SK_DPD_pcb': 0.0}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict([(train_1.columns[i], j) for i, j in enumerate(importance)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a1cb29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d830ddde",
   "metadata": {},
   "source": [
    "\"Теперь переходим к стекингу\"\n",
    "\n",
    "подгрузим чего не хватает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3266ba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "922ba9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = reload_data()\n",
    "train_p = train[train[target] == 1]\n",
    "train_m = train[train[target] == 0].sample(train_p.shape[0])\n",
    "train_1 = train_p.append(train_m)\n",
    "train_1 = join_(train_1)\n",
    "print_object_and_convert_bits(train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f6e47a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = (train_1.drop(target, axis=1), train_1[target]) # надоело копировать"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562cb232",
   "metadata": {},
   "source": [
    "делаем глупую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "83188729",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:30:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:30:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andru/.local/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/andru/.local/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/andru/.local/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/andru/.local/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/andru/.local/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:30:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andru/.local/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5830178039152502"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_learners = [\n",
    "                ('rf_1', RandomForestClassifier(n_estimators=15, random_state=42)),\n",
    "                ('rf_2', KNeighborsClassifier(n_neighbors=5)),\n",
    "                ('rf_3', xgb.XGBClassifier(use_label_encoder=False)),\n",
    "                ('rf_4', xgb.XGBClassifier(use_label_encoder=False)),\n",
    "                ('rf_5', RandomForestClassifier(n_estimators=5, random_state=42))\n",
    "                ]\n",
    "clf = StackingClassifier(estimators=base_learners, final_estimator=RandomForestClassifier(n_estimators=2, random_state=42), cv=5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, stratify=y, random_state=42)\n",
    "clf.fit(X_train.fillna(-1), y_train)\n",
    "clf.score(X_test.fillna(-1), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a248b82e",
   "metadata": {},
   "source": [
    "убираем лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4d1d1358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:32:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:32:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andru/.local/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/andru/.local/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/andru/.local/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/andru/.local/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/andru/.local/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:33:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:34:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andru/.local/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5788286473858052"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_learners = [\n",
    "                ('rf_2', KNeighborsClassifier(n_neighbors=5)),\n",
    "                ('rf_3', xgb.XGBClassifier(use_label_encoder=False)),\n",
    "                ('rf_4', xgb.XGBClassifier(use_label_encoder=False)),\n",
    "                ('rf_5', RandomForestClassifier(n_estimators=5, random_state=42))\n",
    "                ]\n",
    "clf = StackingClassifier(estimators=base_learners, final_estimator=RandomForestClassifier(n_estimators=2, random_state=42), cv=5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, stratify=y, random_state=42)\n",
    "clf.fit(X_train.fillna(-1), y_train)\n",
    "clf.score(X_test.fillna(-1), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3ffed1",
   "metadata": {},
   "source": [
    "Качество предсказаний упало, оценки леса помогали нашему финальному лесу в принятии решений"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
